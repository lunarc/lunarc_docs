{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to the Lunarc Documentation pages\n\n\nHere you will find all of the documentation for the Lunarc resources in a easy to find place.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-the-lunarc-documentation-pages", 
            "text": "Here you will find all of the documentation for the Lunarc resources in a easy to find place.", 
            "title": "Welcome to the Lunarc Documentation pages"
        }, 
        {
            "location": "/login_howto/", 
            "text": "Introduction\n\n\nThe main way of accessing the Lunarc systems are using a terminal and command line tools. To get access to a terminal the user has to login in to Lunarc using a Secure Shell (SSH) terminal client, for example:\n\n\nssh alarik.lunarc.lu.se -l username\n\n\n\nor\n\n\nssh username@alarik.lunarc.lu.se\n\n\n\nOn Linux this client is built-in to the system and no installation is neccesary. Windows does not have a standard SSH terminal so an external application is needed such as PuTTY (http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html) is needed.\n\n\nTo authenticate to the Lunarc system a two-factor authentication solution is used. Two-factor authentication uses two factors for authentication instead of one which is commonly found in normal username and password systems. In the Lunarc case the two factors are:\n\n\nUsername and password.\nOne-time password sent by SMS to a mobile phone.\n\n\n\nWhen you apply for an account the mobile number is registered in our user database and will be used in the login process described in the following sections.\n\n\nLogging in using One Time Passwords (OTP)\n\n\nLogging in to the Lunarc system with OTP passwords is not very different from a normal SSH login, except for the additional extra password prompt. A typical session is shown in the following example:\n\n\nlogin as: joeuser \nPassword: \nPlease enter your onetime password: 123456\n\n\n\nIf the otp and password are correct you will be logged in to the system.\n\n\nLinux\n\n\nTo be prompted for the OTP password the ssh client must be configured for so called \"keyboard-interactive\" login. These settings can be modified in either /etc/ssh/ssh_config (Redhat systems) or in the home-directory ~/.ssh/config. An example configuration is shown below:\n\n\nHost alarik.lunarc.lu.se \nPreferredAuthentications keyboard-interactive\n\nHost * \nPreferredAuthentications hostbased,publickey,keyboard-interactive,password\n\n\n\nIn the above example Platon is configured for keyboard-interactive login, but all other hosts are configured with default login options.\n\n\nTo reduce the number of logins to the system the ServerAlive option can also be added:\n\n\nHost alarik.lunarc.lu.se \nPreferredAuthentications keyboard-interactive \nServerAliveInterval 10\n\nHost * \nPreferredAuthentications hostbased,publickey,keyboard-interactive,password\n\n\n\nMac OS X\n\n\nMac OS X is already configured to handle the login to Platon with one time passwords (keyboard-interactive). \n\n\nTo reduce the number of logins to the system the ServerAlive option can also be added:\n\n\nHost alarik.lunarc.lu.se \nPreferredAuthentications keyboard-interactive \nServerAliceInterval 10\n\nHost * \n    PreferredAuthentications hostbased,publickey,keyboard-interactive,password\n\n\n\nMac OS X 10.7 Lion and 10.8 Mountain Lion\n\n\nTo login to a Lunarc system from a Mac system running Mac OS X 10.7 and 10.8, you need to unset the box \"Set locale environment variables on startup\" in the settings window of the terminal application, press \"cmd ,\" to get there. \n\n\nEnglish example:\n\n\nSetting locale in lion (english)\n\n\nSwedish example:\n\n\nSetting locale in lion (english)\n\n\nNote: This works on a per-theme basis.  In the above examples you will need to choose the theme \"Homebrew\" to connect to the Lunarc servers.\n\n\nWindows\n\n\nTo be prompted for the OTP password the PuTTY client must be configured for so called \"keyboard-interactive\" login. Open PuTTY from the start-menu. Load the session options for Platon. Open the Connection/SSH/Auth item in the tree-view. Make sure the \"Attempt \"keyboard-interactive\" auth (SSH-2) is checked in the settings, see the following image:\n\n\nTo reduce the number of logins to the system the \"Seconds between keepalives\" can be changed to a value greater than 0. See the following figure:\n\n\nFile transfers\n\n\nTo reduce the number of otp passwords needed when transferring files the SFTP protocoll should be used instead of SCP, as each SCP connection will require a new OTP password.\n\n\nFile transfers with WinSCP\n\n\nThe default filetransfer method in WinSCP is SFTP, so no special settings is needed for this. Just make sure that the \"File protocol\" setting is set to SFTP as shown in the following figure:\n\n\nTo reduce the number of logins to the system the \"Keepalive\" options can be set as shown in the following figure:\n\n\nPlease note:\n\n\nthat the \"Advanced options\" checkbox must be checked to access these settings", 
            "title": "How to login"
        }, 
        {
            "location": "/login_howto/#introduction", 
            "text": "The main way of accessing the Lunarc systems are using a terminal and command line tools. To get access to a terminal the user has to login in to Lunarc using a Secure Shell (SSH) terminal client, for example:  ssh alarik.lunarc.lu.se -l username  or  ssh username@alarik.lunarc.lu.se  On Linux this client is built-in to the system and no installation is neccesary. Windows does not have a standard SSH terminal so an external application is needed such as PuTTY (http://www.chiark.greenend.org.uk/~sgtatham/putty/download.html) is needed.  To authenticate to the Lunarc system a two-factor authentication solution is used. Two-factor authentication uses two factors for authentication instead of one which is commonly found in normal username and password systems. In the Lunarc case the two factors are:  Username and password.\nOne-time password sent by SMS to a mobile phone.  When you apply for an account the mobile number is registered in our user database and will be used in the login process described in the following sections.", 
            "title": "Introduction"
        }, 
        {
            "location": "/login_howto/#logging-in-using-one-time-passwords-otp", 
            "text": "Logging in to the Lunarc system with OTP passwords is not very different from a normal SSH login, except for the additional extra password prompt. A typical session is shown in the following example:  login as: joeuser \nPassword: \nPlease enter your onetime password: 123456  If the otp and password are correct you will be logged in to the system.", 
            "title": "Logging in using One Time Passwords (OTP)"
        }, 
        {
            "location": "/login_howto/#linux", 
            "text": "To be prompted for the OTP password the ssh client must be configured for so called \"keyboard-interactive\" login. These settings can be modified in either /etc/ssh/ssh_config (Redhat systems) or in the home-directory ~/.ssh/config. An example configuration is shown below:  Host alarik.lunarc.lu.se \nPreferredAuthentications keyboard-interactive\n\nHost * \nPreferredAuthentications hostbased,publickey,keyboard-interactive,password  In the above example Platon is configured for keyboard-interactive login, but all other hosts are configured with default login options.  To reduce the number of logins to the system the ServerAlive option can also be added:  Host alarik.lunarc.lu.se \nPreferredAuthentications keyboard-interactive \nServerAliveInterval 10\n\nHost * \nPreferredAuthentications hostbased,publickey,keyboard-interactive,password", 
            "title": "Linux"
        }, 
        {
            "location": "/login_howto/#mac-os-x", 
            "text": "Mac OS X is already configured to handle the login to Platon with one time passwords (keyboard-interactive).   To reduce the number of logins to the system the ServerAlive option can also be added:  Host alarik.lunarc.lu.se \nPreferredAuthentications keyboard-interactive \nServerAliceInterval 10\n\nHost * \n    PreferredAuthentications hostbased,publickey,keyboard-interactive,password", 
            "title": "Mac OS X"
        }, 
        {
            "location": "/login_howto/#mac-os-x-107-lion-and-108-mountain-lion", 
            "text": "To login to a Lunarc system from a Mac system running Mac OS X 10.7 and 10.8, you need to unset the box \"Set locale environment variables on startup\" in the settings window of the terminal application, press \"cmd ,\" to get there.   English example:  Setting locale in lion (english)  Swedish example:  Setting locale in lion (english)  Note: This works on a per-theme basis.  In the above examples you will need to choose the theme \"Homebrew\" to connect to the Lunarc servers.", 
            "title": "Mac OS X 10.7 Lion and 10.8 Mountain Lion"
        }, 
        {
            "location": "/login_howto/#windows", 
            "text": "To be prompted for the OTP password the PuTTY client must be configured for so called \"keyboard-interactive\" login. Open PuTTY from the start-menu. Load the session options for Platon. Open the Connection/SSH/Auth item in the tree-view. Make sure the \"Attempt \"keyboard-interactive\" auth (SSH-2) is checked in the settings, see the following image:  To reduce the number of logins to the system the \"Seconds between keepalives\" can be changed to a value greater than 0. See the following figure:", 
            "title": "Windows"
        }, 
        {
            "location": "/login_howto/#file-transfers", 
            "text": "To reduce the number of otp passwords needed when transferring files the SFTP protocoll should be used instead of SCP, as each SCP connection will require a new OTP password.", 
            "title": "File transfers"
        }, 
        {
            "location": "/login_howto/#file-transfers-with-winscp", 
            "text": "The default filetransfer method in WinSCP is SFTP, so no special settings is needed for this. Just make sure that the \"File protocol\" setting is set to SFTP as shown in the following figure:  To reduce the number of logins to the system the \"Keepalive\" options can be set as shown in the following figure:  Please note:  that the \"Advanced options\" checkbox must be checked to access these settings", 
            "title": "File transfers with WinSCP"
        }, 
        {
            "location": "/quick_reference/", 
            "text": "Useful hints and short information on issues that may vary between the different systems\n\n\nInstalled softwared software\n\n\nTo see the installed software available through the modules system, issue the command\n\n\nmodule avail\n\n\n\nTo see the currently loaded modules\n\n\nmodule list\n\n\n\nTo load a module\n\n\nmodule add \nmodule_name\n\n\n\n\nTo unload a module\n\n\nmodule del \nmodule_name\n\n\n\n\nResource allocation\n\n\nNumber of cores\n\n\nThe number of cores for a job is specified in the batch script in the format\n\n\n#SBATCH -N \nnumber_of_nodes\n\n#SBATCH --tasks-per-node=\nnumber_of_cores_per_node\n\n\n\n\nAlarik has 16 cores per node. On this system, 64 cores would be allocated through\n\n\n# 64 cores on Alarik\n#SBATCH -N 4 #SBACTH --tasks-per-node=16\n\n\n\nMemory per core\n\n\nThe amount of memory per core is specified in the format\n\n\n#SBATCH --mem-per-cpu=\namount_of_memory_per_core_in_MB\n\n\n\n\nAlarik has nodes with 32 GB and 64 GB memory. The default allocation per core is therefore 2000 MB to match the smaller memory. To fully utilise the memory on the 64 GB nodes, the nodes have to requested specifically with \n-C mem64GB\n and the memory per core should be set to 4000 MB .\n\n\n# Twice the default amount of memory per core on Alarik nodes with 64 GB memory \n#SBATCH -C mem64GB #SBATCH --mem-per-cpu=4000\n\n\n\nFile systems\n\n\nHome directory\n\n\nCurrently all Lunarc systems have a home directory that is different for each system, i.e., the login directory for user xxxx is\n\n\n/home/xxxx\n\n\n\nThis directory can be referenced as \n$HOME\n.\n\n\nAs a rule, the home directory should not be used for job submission. It is intended for storing important files, such as the source code of user programs, and, of course, environment files, such as .bashrc.\n\n\nGlobal working directory\n\n\nFor job submission, there is a centre file system common to all Lunarc systems:\n\n\n/lunarc/nobackup/users/xxxx\n\n\n\nHere the xxxx has to be replaced with your userid.\n\n\nLocal working directory\n\n\nWhen a job is running, it has access to a temporary directory on the local disk of each allocated node. The directory can be referenced as \n$SNIC_TMP\n (or \n$TMPDIR\n). It will be deleted when the job finishes.\n\n\nIf a job is terminated prematurely, for example, if it exceeds the requested walltime, the files on the local disk will be lost. Files that would still be useful can be listed in a special file \n$SNIC_TMP/slurm_save_files\n. Filenames are assumed to be relative to \n$SNIC_TMP\n and should be separated by spaces or listed on separate lines. These files will be copied to the submission directory regardless whether the job ends as planned or is deleted, unless there is a problem with the disk or node itself.\n\n\nQuotas\n\n\nTo limit the disk usage, quotas are set for each user and filesystem. The status can be seen at login. A quota report can also be obtained by issuing the command\n\n\nsnicquota\n\n\n\nThe quota can be increased on request.\n\n\nTest queues\n\n\nOn Alarik, it is possible to request extra high priority to run short tests (maximum 1h) using at most 2 nodes using\n\n\n#SBATCH --qos=test\n\n\n\nFloating reservations are used to free two nodes every second hour between 8.00 and 20.00 to reduce the queue time for test jobs, which means that a shorter walltime increases likelihood of an earlier start. Only two such test jobs are allowed to run at the same time.\n\n\nOn Erik there is one two-GPU node reserved for tests (maximum 1 h) in a partition of its own, which is specified with\n\n\n#SBATCH -p test\n\n\n\nIt is not allowed to submit long series of jobs to a test queue.", 
            "title": "Quick reference"
        }, 
        {
            "location": "/quick_reference/#installed-softwared-software", 
            "text": "To see the installed software available through the modules system, issue the command  module avail  To see the currently loaded modules  module list  To load a module  module add  module_name   To unload a module  module del  module_name", 
            "title": "Installed softwared software"
        }, 
        {
            "location": "/quick_reference/#resource-allocation", 
            "text": "", 
            "title": "Resource allocation"
        }, 
        {
            "location": "/quick_reference/#number-of-cores", 
            "text": "The number of cores for a job is specified in the batch script in the format  #SBATCH -N  number_of_nodes \n#SBATCH --tasks-per-node= number_of_cores_per_node   Alarik has 16 cores per node. On this system, 64 cores would be allocated through  # 64 cores on Alarik\n#SBATCH -N 4 #SBACTH --tasks-per-node=16", 
            "title": "Number of cores"
        }, 
        {
            "location": "/quick_reference/#memory-per-core", 
            "text": "The amount of memory per core is specified in the format  #SBATCH --mem-per-cpu= amount_of_memory_per_core_in_MB   Alarik has nodes with 32 GB and 64 GB memory. The default allocation per core is therefore 2000 MB to match the smaller memory. To fully utilise the memory on the 64 GB nodes, the nodes have to requested specifically with  -C mem64GB  and the memory per core should be set to 4000 MB .  # Twice the default amount of memory per core on Alarik nodes with 64 GB memory \n#SBATCH -C mem64GB #SBATCH --mem-per-cpu=4000", 
            "title": "Memory per core"
        }, 
        {
            "location": "/quick_reference/#file-systems", 
            "text": "", 
            "title": "File systems"
        }, 
        {
            "location": "/quick_reference/#home-directory", 
            "text": "Currently all Lunarc systems have a home directory that is different for each system, i.e., the login directory for user xxxx is  /home/xxxx  This directory can be referenced as  $HOME .  As a rule, the home directory should not be used for job submission. It is intended for storing important files, such as the source code of user programs, and, of course, environment files, such as .bashrc.", 
            "title": "Home directory"
        }, 
        {
            "location": "/quick_reference/#global-working-directory", 
            "text": "For job submission, there is a centre file system common to all Lunarc systems:  /lunarc/nobackup/users/xxxx  Here the xxxx has to be replaced with your userid.", 
            "title": "Global working directory"
        }, 
        {
            "location": "/quick_reference/#local-working-directory", 
            "text": "When a job is running, it has access to a temporary directory on the local disk of each allocated node. The directory can be referenced as  $SNIC_TMP  (or  $TMPDIR ). It will be deleted when the job finishes.  If a job is terminated prematurely, for example, if it exceeds the requested walltime, the files on the local disk will be lost. Files that would still be useful can be listed in a special file  $SNIC_TMP/slurm_save_files . Filenames are assumed to be relative to  $SNIC_TMP  and should be separated by spaces or listed on separate lines. These files will be copied to the submission directory regardless whether the job ends as planned or is deleted, unless there is a problem with the disk or node itself.", 
            "title": "Local working directory"
        }, 
        {
            "location": "/quick_reference/#quotas", 
            "text": "To limit the disk usage, quotas are set for each user and filesystem. The status can be seen at login. A quota report can also be obtained by issuing the command  snicquota  The quota can be increased on request.", 
            "title": "Quotas"
        }, 
        {
            "location": "/quick_reference/#test-queues", 
            "text": "On Alarik, it is possible to request extra high priority to run short tests (maximum 1h) using at most 2 nodes using  #SBATCH --qos=test  Floating reservations are used to free two nodes every second hour between 8.00 and 20.00 to reduce the queue time for test jobs, which means that a shorter walltime increases likelihood of an earlier start. Only two such test jobs are allowed to run at the same time.  On Erik there is one two-GPU node reserved for tests (maximum 1 h) in a partition of its own, which is specified with  #SBATCH -p test  It is not allowed to submit long series of jobs to a test queue.", 
            "title": "Test queues"
        }, 
        {
            "location": "/batch_system/", 
            "text": "Using the job submission system on Alarik and Erik\n\n\nJoachim Hein, Jonas Lindemann, Anders Sj\u00f6str\u00f6m, Magnus Ullner\n\n\nDocument under active development - Check back frequently!\n\n\nA more in-depth guide to the job submission system on Alarik and Erik.\n\n\nSLURM - the batch system on Alarik and Erik\n\n\nOn a modern HPC system efficient management of the compute resources is\nabsolutely crucial for the system to perform. Alarik and Erik are the\nfirst Lunarc systems to deploy SLURM (\nS\nimple \nL\ninux \nU\ntility\nfor \nR\nesource \nM\nanagement) as resource manager. For your program\nto be executed you have to describe to SLURM the resources required by\nyour program, the name of your program and the command line arguments\nyour program may require. SLURM also allows monitoring and manipulation\nof the progress of your programs execution.\n\n\nThis document contains two key parts. The \nfirst\npart\n describes in-depth the job submission system\nand its options. The \nsecond part\n gives example\nscripts for the most common use cases. They hopefully serve as a good\nstarting point when creating submission scripts fitting your needs and\nrequirements.\n\n\nJob submission\n\n\nFirst example for a job submission\n\n\nThe job script and sbatch\n\n\nYou register your program with SLURM for execution using the \nsbatch\n\ncommand. This is done easiest by using a \njob description file\n. The job\ndescription file is also know as a \njob script\n.\n\n\nA very simple job script, looks as follows:\n\n\n#!/bin/sh\n#SBATCH -t 00:05:00\n\necho \"hello\"\n\n\n\nWrite this into a file. In the following we assume the file is named\necho_script.sh, but in principle any name will do. You can now send the\nscript for execution using the sbatch command. This will execute the\n\u201cprogram\u201d echo on the backend.\n\n\nsbatch echo_script.sh\n\n\n\nThis should deliver a screen output similar to\n\n\n[fred@alarik Serial]$ sbatch echo_script.sh\nSubmitted batch job 7185\n\n\n\nWhere 7185 is the job number assigned by SLURM. Once your job has\nexecuted you will find a file slurm-7185.out in your directory which\ncontains the output and error messages from your program.\n\n\nThe three parts of a job script\n\n\nThe example echo_script.sh shows the three parts every job script\nrequires\n\n\n\n\nShell specification\n\n\nResource statement\n\n\nBody containing a UNIX script\n\n\n\n\nIn our example each part consists of a single line. The first line of\nour example contains the shell specification, in most cases the sh-shell\nas used here is just fine. The second line starting with #SBATCH\nspecifies the resources needed. In our case it asks for 10 minutes of\ncomputer time. If the jobs hasn\u2019t finished after that time, SLURM will\nterminate it. Job scripts typically contain more than one of these\nstatements, specifying e.g. more than one processor or more memory. The\nmost commonly used resource statements at Lunarc will be explained\nbelow. The resource statements are followed by a list of programs and\nUNIX commands to be executed on the system. This is actually a normal\nUNIX script and everything you can do in a UNIX script can be done here\nas well. In our example the script consists out of the UNIX echo\ncommand.\n\n\nResource statements for all jobs\n\n\nWe now describe a number of statements which are most commonly used to\nspecify resource requirements for all kind of jobs. Refer to \u201cman\nsbatch\u201d for more information.\n\n\nWalltime\n\n\nThe walltime attribute specifies the time requested for completing the\njob. The time is \nnot\n cpu-time but the total time, as measured by a\nnormal clock. In the previous example the time requested was 0 hours 5\nminutes and 0 seconds. Walltime is specified in seconds or using the\nfollowing notation:\n\n\nHours:Minutes:Seconds\n\n\n\nIf your calculation hasn\u2019t finished once the specified time has elapsed,\nSLURM will terminate your job. It is therefore \ngood practise\n to\nspecify a bit more time than you anticipate your job to take. This makes\nsure that you still get your results, even the jobs is slowed by some\ninterference, e.g. waiting for a write to a shared file system to\nfinish. However don\u2019t specify excessive extra time. Due to scheduling\nconstraints, jobs asking for less time will typically spend less time in\nthe queue, waiting for their execution. This also provides safety\nagainst depletion of your allocation. If, e.g., your job hangs, SLURM\nwill terminate your job and the project will be charged less time if the\nwalltime margin is not excessive.\n\n\nTo specify your walltime requirements write a statement like\n\n\n#SBATCH -t 00:10:00\n\n\n\ninto your job script.\n\n\nThe maximum walltime for any job on Alarik is 168h, which is the same as\n7 days. On Erik the maximum walltime for any job is 48h.\n\n\nJob naming\n\n\nAll jobs are given both a job identifier and a name, for easier\nidentification in the batch-system. The default name given to a job is\nthe file name of the submit script, which can make it difficult to\nidentify your job, if you use a standard name for your submit scripts.\nYou can give your job a name from inside the script by using the -J\noption:\n\n\n#SBATCH -J parameterTest\n\n\n\nThis will name your job \u201cparameterTest\u201d.\n\n\nSpecifying a project for users with multiple projects\n\n\nMost users are members of only one project. These users do not need to\nspecify a project in their in their submission script. The Lunarc set-up\nwill automatically use that project for accounting.\n\n\nA few users are members of more than project. In this case the system\nwould not know which project to charge for the run, so you need to\nspecify the project using the -A option:\n\n\n#SBATCH -A snic2015-x-xxx\n\n\n\nReplace the \u201csnic2015-x-xxx\u201d with the string naming your project. You\ncan inquire the correct string using the projinfo command or the SUPR\nsystem.\n\n\nSpecifying memory requirements\n\n\nAlarik has 32 GB of memory installed on the small memory nodes and 64 GB\nof memory on the large memory nodes. The default memory request per core\non the system is 2000 MB (a sixteenth of 32GB). If more then 2000 MB per\ncore is needed it has to be requested explictly with the\n\n--mem-per-cpu\n option of sbatch. In this case you also have to\nrequest allocation on a large memory node using the \n-C mem64GB\n\noption of sbatch. The following show an example how to request 4000 MB\nor main memory per compute core used:\n\n\n#SBATCH -C mem64GB\n#SBATCH --mem-per-cpu=4000\n\n\n\nWhen requesting more than 2000 MB of memory, your jobs may spend a\nlonger time in the queue, waiting for execution, since it needs to wait\nfor run-slot(s) on the large memory nodes to become available. When\nrequesting more then 4000 MB per processing core, your jobs will be\ncharged at a higher rate. In this case some processing cores have to\nremain idle since you are using more than your fair share of memory.\n\n\nErik has 64 Gb of memory on the standard nodes. Each node has two CPUs\nwith eight cores each. The default memory request per core is therefore\n4000 MB of memory. As in the case of Alarik, if more than 4000MB of\nmemory per core is needed it has to be described as above.\n\n\nControlling job output\n\n\nBy default, the output which your job writes to stdout and stderr is\nwritten to a file named\n\n\nslurm_%j.out\n\n\n\nThe %j in the file name will be replaced by the jobnumber SLURM assigns\nto your job. This ensures that the output file from your job is unique\nand different jobs do not interfere with each other's output file.\n\n\nIn many cases the default file name is not convenient. You might want to\nhave a file name which is more descriptive of the job that is actually\nrunning - you might even want to include important meta-data, such as\nphysical parameters, into the output filename(s). This can be achieved\nby using the -o and -e options of sbatch. The -o option specifies the\nfile containing the stdout and the -e option the file containing the\nstderr. It is good practise to include the %j string into the filenames.\nThat will prevent jobs from overwriting each other's output files. The\nfollowing gives an example:\n\n\n#SBATCH -o calcflow_m1_%j.out\n#SBATCH -e calcflow_m1_%j.err\n\n\n\nYou can give the same filename for both options to get stdout and stderr\nwritten to the same file.\n\n\nNotification\n\n\nSLURM on the systems can send you email if the status of your job\nchanges as it progresses through the job queue. To use this feature you\nneed to specify the email address using the --mail-user option and\nspecify the event you want to get notified about using the --mail-type\noption. The following\n\n\n#SBATCH --mail-user=fred@institute.se\n#SBATCH --mail-type=END\n\n\n\nWill send an email to the address fred@institute.se once the job has\nended. Valid type values, selecting the event you can get notified\nabout, are BEGIN, END, FAIL, REQUEUE, and ALL (any state change).\n\n\nJob dependencies\n\n\nTo describe job dependencies, use the -d option of sbatch. This is\nparticularly useful for job dependencies, in workflows.\n\n\nTo illustrate this consider the following example. You require a serial\njob to create a mesh for your simulation. Once this has finished, you\nwant to start a parallel job, which uses the mesh. You first submit the\nmesh creation job using sbatch\n\n\n[fred@alarik Simcode]$ sbatch run_mesh.sh\nSubmitted batch job 8042\n\n\n\nAs discussed, sbatch returns you a jobid, 8042 in this example. You use\nthis to declare your dependency when submitting the simulation job to\nthe queue\n\n\n[fred@alarik Simcode]$ sbatch -d afterok:8042 run_sim.sh\nSubmitted batch job 8043\n\n\n\nWhen using squeue to monitor job 8043, this should now be in status\npending (PD) with the reason of dependency. Another common use case for\nthis functionality is a simulation requiring many days of computer times\nbeing split into a number of submissions.\n\n\nTest queue\n\n\nTo run short tests, it is possible to request extra high priority on\nAlarik with the help of\n\n\n#SBATCH --qos=test\n\n\n\nFor one such job, the maximum walltime is 1 h and the maximum number of\nnodes is two and a user is only allowed to run two such jobs\nsimultaneously. A system of floating reservations is used to free two\nnodes every second hour between 8.00 and 20.00 to reduce the queue time\nfor test jobs. The way it works also means that the shorter the test\njob, the more likely it is to start sooner rather than later. It is not\nallowed to use qos=test for series of production runs.\n\n\nOn Erik there is one two-GPU node reserved for tests in a partition of\nits own, which is specified with\n\n\n#SBATCH -p test\n\n\n\nLike on Alarik, the maximum walltime is 1 h.\n\n\nExtra fat nodes on Alarik\n\n\nAlarik has four nodes with 48 cores and 128 GB memory. To access them,\nthe partition extra has to be specified\n\n\n#SBATCH -p extra\n\n\n\nFurthermore, the amount of memory per requested core also needs to be\ngiven.\n\n\n#SBATCH --mem-per-cpu=\nmemory in MB\n\n\n\n\nOtherwise, the default value of 2 000 MB will be set at and if more is\nused, slurm can kill the job. For example, to run on the 48 cores of a\nsingle node and use a total of 128 000 MB of memory (for more on\nmultiprocessor statements, see the next section):\n\n\n#SBATCH -N 1\n#SBATCH --tasks-per-node=48\n#SBATCH --mem-per-cpu=3000\n#SBATCH -p extra\n\n\n\nFat, extra fat and MIC nodes on Erik\n\n\nErik has 7 nodes with 4 GPUs (and 96 GB of memory). To access them, the\npartition fat has to be specified\n\n\n#SBATCH -p fat\n\n\n\nOne node is equipped with 8 GPUs (and 96 GB of memory), which is in\npartition extra\n\n\n#SBATCH -p extra\n\n\n\nThere is also one node with two Xeon Phi (MIC) cards in the partition\nmic\n\n\n#SBATCH -p mic\n\n\n\nThere is also one node with two Nvidia K80 cards in the partition new\n\n\n#SBATCH -p new\n\n\n\nIf no -p option is specified, normal nodes with two Nvidia K20 cards\nwill be allocated to the job.\n\n\nResource statements for multiprocessor\n\n\nIn HPC it is very common to have many processing elements working on a\njob. The extra processing power can be utilised to process large\nproblems beyond the capabilities of a single processing element. It can\nalso be used to swiftly perform a number of calculations within a single\njob submission.\n\n\nTerminology around nodes, processors, cores, tasks\n\n\nThere is a a lot of structure within modern HPC equipment. For the\npurposes of this user guide we will stick to the following terminology:\n\n\n\n\n\n\n\n\nTerm\n\n\nExplanation\n\n\nNumber on Alarik\n\n\nNumber  on Erik\n\n\n\n\n\n\n\n\n\n\nNode\n\n\nA physical computer\n\n\nStandard:\n\n\nStandard:\n\n\n\n\n\n\n\n\n\n\n200\n\n\n16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra:\n\n\nFat:\n\n\n\n\n\n\n\n\n\n\n4\n\n\n7\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra:\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMic:\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew:\n\n\n\n\n\n\n\n\n\n\n\n\n1\n\n\n\n\n\n\nProcessor\n\n\nThis denotes a the multi-core processor, housing many processing elements\n\n\nStandard:\n\n\n2 per node\n\n\n\n\n\n\n\n\n\n\n2 per node\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra:\n\n\n\n\n\n\n\n\n\n\n\n\n4 per node\n\n\n\n\n\n\n\n\nGPU\n\n\nThis denotes a nvidia co-processor\n\n\n0\n\n\nStandard:\n\n\n\n\n\n\n\n\n\n\n\n\n2 per node\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFat:\n\n\n\n\n\n\n\n\n\n\n\n\n4 per node\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra:\n\n\n\n\n\n\n\n\n\n\n\n\n8 per node\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMic:\n\n\n\n\n\n\n\n\n\n\n\n\n0 per node\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNew:\n\n\n\n\n\n\n\n\n\n\n\n\n2 cards per node\n\n\n\n\n\n\n\n\n\n\n\n\n2 logical per card\n\n\n\n\n\n\n\n\n\n\n\n\n4 logical per node\n\n\n\n\n\n\nSocket\n\n\nThis is the \u201cplug\u201d the processor gets plugged into.  Used as a synonym for the processor\n\n\nStandard:\n\n\n2 per node\n\n\n\n\n\n\n\n\n\n\n2 per node\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra:\n\n\n\n\n\n\n\n\n\n\n\n\n4 per node\n\n\n\n\n\n\n\n\nCore\n\n\nIndividual processing element\n\n\nStandard:\n\n\n16 per node\n\n\n\n\n\n\n\n\n\n\n16 per node\n\n\n8 per processor\n\n\n\n\n\n\n\n\n\n\n8 per processor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtra:\n\n\n\n\n\n\n\n\n\n\n\n\n48 per node\n\n\n\n\n\n\n\n\n\n\n\n\n12 per processor\n\n\n\n\n\n\n\n\nTask\n\n\nThis is a software concept.  It denotes a process, which is an instance of a running program.  It has its own data and instruction stream(s).  It can fork multiple threads to increase the computational speed.  Serial programs and pure MPI programs do not spawn threads.\n\n\nUser controls in job script\n\n\nUser controls in job script\n\n\n\n\n\n\nThread\n\n\nThis is also a software concept.  A thread is a stream of instructions executed on the hardware.  It is part of a task and shares resources such as  data with other threads within the same task.\n\n\nUser controls in job script\n\n\nUser controls in job script\n\n\n\n\n\n\n\n\nOutline: Resource requests for multiprocessor jobs\n\n\nWhen running multi processor jobs on the Lunarc clusters, one should\nspecify:\n\n\n\n\nThe number of nodes required by the jobs\n\n\nThe number of computational tasks per node\n\n\nThe number of threads spawned by each task\n\n\n\n\nFor a pure MPI job or when processing a large number of serial jobs in a\nso called task farm, one will typically only specify the items 1 and 2,\nwhile for a threaded job, using e.g. OpenMP or Java, one will typically\nonly specify items 1 and 3.\n\n\nIt is typically not advisable to have the product of items 2 and 3\nexceeding the number of cores per node, which is 16 for standard Alarik\nand Erik compute nodes. On the Alarik extra compute nodes this number is\n48. In most cases users requesting multiple nodes will want the product\nto equal the number of cores per node. The syntax how to control nodes,\ntasks per node and threads per task is explaned below.\n\n\nExclusive node access\n\n\nFor parallel codes using MPI or OpenMP it is typically best to keep\ninterference on the nodes at a minimum, that is to have exclusive access\nto the nodes you are using. This also applies to specialist and\nexperimental work, which would interfere very badly with other user\u2019s\ncodes on the nodes. Adding\n\n\n#SBATCH --exclusive\n\n\n\nto your job script will ensure that SLURM will allocate dedicated nodes\nto your job. Obviously your project gets charged for the full costs of\nthe nodes you are using, that is in case of Alarik and Erik 16 cores per\nnode.\n\n\nSpecifying the number of nodes required for the job\n\n\nIn SLURM one requests the number of nodes for a job with the \n-N\n\noption. The following statement requests four nodes for your job:\n\n\n#SBATCH -N 4\n\n\n\nImportant:\n without using either the --tasks-per-node or\nthe --cpus-per-task options of sbatch, this will reserve a single core\nper node, so four in total, which is most likely not what you want.\n\n\nSpecifying the number of tasks per node\n\n\nUse the --tasks-per-node of sbatch to specify the number of tasks you\nrequire per node. Most multinode job will set this equal to the number\nof cores availble per node. The following example asks for 16 task per\nnode:\n\n\n#SBATCH --tasks-per-node=16\n\n\n\nThis should be used together with the -N option, specifying the number\nof nodes to be used. The default value for the number of tasks per node\nis 1. For example to specify the requirements for an MPI job with 64\ntasks or multiprocessor job using 64 processors to process a larger\nnumber of serial jobs one would specify\n\n\n#SBATCH -N 4\n#SBATCH --tasks-per-node=16\n\n\n\nWhen using fewer than 16 tasks per node and you want to prevent other\nuser\u2019s jobs sharing your node, you need to consider using\nthe --exclusive option. If --exclusive is not specified, SLURM might\nplace other tasks onto your node.\n\n\nSpecifying the number of threads for a shared-memory job\n\n\nIf you want to run shared-memory applications using threads, e.g. OpenMP\nparallised code or Java applications, you need to specify the number of\nthreads you require per task. This can be done with the --tasks-per-node\noption of sbatch.\n\n\nFor a standard shared-memory program, which doesn\u2019t also use distributed\nmemory programming models such as MPI, one is restricted to a single\nnode. On that node, one can request as many threads as there are cores\non the node. On the standard Alarik compute nodes one can efficiently\nuse up to 16 threads. Use the following resource statement:\n\n\n#SBATCH -N 1\n#SBATCH --tasks-per-node=16\n\n\n\nIf your program is only efficient at a lower thread count, you may want\nto use e.g.:\n\n\n#SBATCH -N 1\n#SBATCH --tasks-per-node=4\n\n\n\nif you only want to use four threads. The Alarik extra nodes with 48\ncores allow for very wide shared-memory jobs:\n\n\n#SBATCH -N 1\n#SBATCH --tasks-per-node=48\n#SBATCH --mem-per-cpu=3000\n#SBATCH -p extra\n\n\n\nResource statements for hybrid programs using distributed and shared memory\n\n\nSo-called hybrid programs, using both distributed and shared-memory\ntechniques have recently become popular. For example: for a program\nusing 32 MPI tasks, each task spawning 2 OpenMP threads one would\nrequire 4 nodes and place eight tasks on each node. The number of\nthreads per task is given by --cpus-per-task. The resource statement\nwould look as follows:\n\n\n#SBATCH -N 4\n#SBATCH --tasks-per-node=8\n#SBATCH --cpus-per-task=2\n\n\n\nSpecifying the number of cores to be required by the job\n\n\nIn special cases, such as using very unusal numbers of tasks, the \n-n\n\noption of sbatch to specify the number of cores might become useful.\nWhen running a pure MPI program this option corresponds to the \nnumber\nof tasks\n required for your program. The following statement in a job\nscript would reserve 63 cores for your job\n\n\n#SBATCH -N 4\n#SBATCH --tasks-per-node=16\n#SBATCH -n 63\n\n\n\nPlease consider using the --exclusive option of sbatch to avoid SLURM\nspreading your job on more nodes than necessary and placing other user\u2019s\njobs on nodes utilising fewer than 16 cores for your job. Other user\u2019s\njobs could via shared node resources (memory bus, cache, FPU, \u2026)\ninterfere with your job and introduce undue operational noise. Such\nnoise is something parallel program execution can be extremely sensitive\nto.\n\n\nProgram execution environment\n\n\nJob execution environment\n\n\nWhen submitting your job to SLURM using sbatch, your entire environment\nincluding the currently loaded modules gets copied. This behaviour is\ndifferent from earlier Lunarc machines, including Platon. On Alarik,\nwhen hitting sbatch:\n\n\n\n\nMake sure that the loaded modules and any environment variable you may have set will not be in conflict with the environment expected by the job script\n\n\n\n\nCompiler modules\n\n\nOn Alarik we automatically load a modern version of the GCC compiler,\nwhich supports the deployed AMD Opteron processors. At the time of\nwriting this is version 4.6.2 of GCC. If you prefer using a different\ncompiler, you can add the desired module, e.g., version 12.1 of the\nIntel compiler\n\n\nmodule add intel/12.1\n\n\n\nIf different modules have files with the same names in the search path,\nthose of the module added last will be picked. Generally this is not a\nproblem, but the compiler wrappers in the openmpi modules have the same\nnames and it safest to only have one loaded at a time.\n\n\nOn Erik the same compilers as on Alarik are present. Note that the\nprocessors on Erik are of the Intel Xeon type and thus utilize the mkl\nas supplied.\n\n\nSLURM variables\n\n\nTo come\n\n\nSNIC variables\n\n\nThe SNIC meta-centres have agreed on a set of environment variables\nwhich should improve the portability of (parts of) job-scripts between\nSNIC sites. On Alarik the following variables are set by the system:\n\n\n\n\nEnvironment variable\n   \nExplanation\n                                                                               \nValue on Alarik\n   \nValue on Erik\n\n\n\n\nSNIC_SITE                 Identifying the SNIC site you are using                                                       lunarc                lunarc\n\n\nSNIC_RESOURCE             Identifying the compute resource you are using                                                alarik                erik\n\n\nSNIC_BACKUP               User directory which is:                                                                      /home/\n        /home/\n\n\n                         \n Regularly backed up against accidental deletion\n\n                         \n Typically extremely limited space\n\n                         \n Use for e.g. precious source code\n\n\n\nSNIC_NOBACKUP             User directory which is:                                                                      /lunarc               /lunarc\n\n\n                         \n Accessible on all Lunarc systems                                                            /nobackup             /nobackup\n\n                         \n Outliving individual systems                                                                /users/\nuser\n       /users/\nuser\n\n\n                         \n For storing larger amounts of data\n\n                         \n Not backed up against accidental deletion\n\n                         \n Protected against disk failure (RAID configuration)\n\n                         \n On Alarik: the primary root directory for job management (job scripts, input/output data)\n\n\n\nSNIC_TMP                  Directory for best performance during a job                                                   \njobid dependent\n     \njobid dependent\n\n\n                         At Lunarc:\n\n                         \n Local disk on nodes\n\n                         \n Storing temporary data during job execution\n\n                         \n High bandwidth\n\n                         \n Automatically deleted\n\n                         \n Transfer data with long-term value to SNIC_NOBACKUP before job has finished\n\n\n\n\n\nUsing the node local disks to improve I/O performance\n\n\nOn Alarik and Erik, all nodes have a local disk. This disk offers\nsuperior bandwidth when compared to accessing your home space or the\n/lunarc/nobackup centre storage. In particular when files are read or\nwritten repeatedly during execution it is advisable to copy the input\ndata onto the local disk prior to job execution and copy the result\nfiles back to the submission directory once your program has finished.\nDuring its execution, your program would then read and write to local\ndisk.\n\n\nIn case of Alarik and Erik, the submission directory typically resides\non the /lunarc/nobackup centre storage. All data left on the node local\ndisks \nwill be deleted\n when your job has finished. You need to copy\neverything of interest to a more permanent storage space such as\n/lunarc/nobackup. If a job is terminated prematurely, for example, if it\nexceeds the requested walltime, the files on the local disk (in\n$SNIC_TMP) will be lost.\n\n\nFiles that would still be useful can be listed in a special file\n\n$SNIC_TMP/slurm_save_files\n. Filenames are assumed to be relative\nto $SNIC_TMP and should be separated by spaces or listed on separate\nlines. Wildcards are allowed. These files will be copied from the local\ndisk where $SNIC_TMP/slurm_save_files exists to the submission\ndirectory regardless whether the job ends as planned or is deleted,\nunless there is a problem with the disk or node itself. Note that the\nslurm_save_files feature is unique to Lunarc.\n\n\nFor the required UNIX scripting you should use the following environment\nvariables. Example scripts using this technique are provided in the\nexample section of this document. Contact the help desk if you have\nspecific requirements and require consultation.\n\n\n\n\nVariable\n         \nAddressed Volume\n\n\n\n\nSNIC_TMP            node local disk\n\n\n                   copy your input data here and start your program from here\n\n\n\nTMPDIR               node local disk\n\n\n                   Many applications use this environment variable to locate a disk volume for temporary scratch space. If your application follows that convention nothing needs to be done.\n\n\n\nSLURM_SUBMIT_DIR   submission directory\n\n\n                   where you ran sbatch\n\n\n\n\n\nLaunching MPI jobs in OpenMPI\n\n\nTo execute message passing parallel jobs these should be built against\none of the MPI libraries provided by the support team as a module. To\nexecute an MPI job, your job script should do the following\n\n\n\n\nLoad MPI module relevant for the compiler you are using\n\n\nStart the program with mpirun\n\n\nOn Alarik the correct binding is crucial to achieve good\n    \n performance. When using 16 task per node, we recommend using\n    \n the -bind-to-core option of mpirun. When using fewer than 16 tasks\n    \n we recommend experimenting whether not using binding helps or\n    \n hinders performance.\n\n\n\n\nSubmitting, monitoring and manipulating jobs in SLURM\n\n\nSubmitting with sbatch\n\n\nOne uses the command sbatch to submit a job script to the batch system\nfor execution. SLURM will reply with the jobid number. The job will then\nbe held in the queue until the requested resources become available. A\ntypical use case looks as follows:\n\n\n[fred@alarik MPItest]$ sbatch runjob.sh\nSubmitted batch job 7197\n\n\n\nUser fred submitted the script runjob.sh to the job queue and got the\njobid 7197 assigned to it.\n\n\nStarting executables within SLURM with srun\n\n\nThe command srun allows to start executables in a way managed by SLURM.\nThis is particularly effective if you want to process a large number of\njobs within a single submission to the batch system. A use case of srun\nto start many serial jobs in a single multicore submission scipt is\ndiscussed in the \nexample section\n.\n\n\nMonitoring with squeue\n\n\nThe command squeue will show you the current state of the job queue. The\nstandard output, created by calling squeue without any options looks as\nfollows:\n\n\nJOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)\n7303 snic hybrid_n fred PD 0:00 32 (Priority)\n7302 snic hybrid_n fred PD 0:00 32 (Priority)\n7301 snic hybrid_n fred PD 0:00 32 (Resources)\n7304 snic preproce karl PD 0:00 6 (Priority)\n7300 snic hybrid_n fred R 0:24 32 an[001-032]\n7305 snic preproce karl R 0:37 6 an[081-086]\n7306 snic hybrid_n fred R 0:37 6 an[081-086]\n7307 snic testsimu sven R 0:07 1 an081\n\n\n\nThe first column gives the jobid, the third the job names, followed by\nthe userid. The column labeled \u201cST\u201d gives the job state. The most\nimportant states are:\n\n\n\n\nSymbol\n   \nMeaning\n\n\n\n\n\n\nR          running\n\n\n\n\nPD           pending, awaiting resources\n\n\nCG           completing\n\n\n\n\nThe state column is followed by the time used by the job and number of\nnodes utilised by the job. For running jobs the last column gives the\nnames of the nodes utilised or if the job is waiting a reason why it is\nnot executing.\n\n\nThe squeue command is highly configurable. Useful options include -u\nmyid, which lists all jobs of the user myid and also the --start option.\nThe latter gives the current estimate of when SLURM expects the job to\nstart. Note, that this can shift in either direction, depending on e.g.\njobs finishing earlier than specified or jobs with higher priority\ngetting added to the job queue.\n\n\nThe command jobinfo is a script that sorts the output of squeue into\nrunning and waiting jobs. It also shows additional information, such as\nhow long running jobs have left and in some cases when waiting jobs are\nexpected to start.\n\n\nTerminating jobs with scancel\n\n\nIt is frequently required to remove jobs from the queue. This might be\nthat you discover a problem in your job specification or intermediate\nresults of running job indicating that something went wrong. Use scancel\nto remove a job from the job queue. To do so you need the jobid, which\nis best queried with the squeue command. To remove the job with the\njobid 7103 from the job queue type\n\n\nscancel 7103\n\n\nExample job scripts\n\n\nIn this section we provide sample scripts for typical use cases.\n\n\nJob scripts using the node local disk\n\n\nBasic run script\n\n\nAs discussed the node local disk provides better I/O-bandwidth than the\nother file systems available on Alarik. The following script assumes the\nprogram processor reads the file \ninput.dat\n and produces a file\n\nresult.dat\n.\n\n\nThis example executes a single serial program and is suitable for the\noccasional serial job. If you need to process a large number of serial\njobs, we request you bundle them into a single submission. Refer to the\nsection \u201c\nR\nunning multiple serial jobs within a\nsingle job submission\n\u201d for a scripting example.\n\n\nThe script copies the input data and the program executable from the\nsubmission directory to the node local disk, executes the program on the\nnode local disk and copies the result file back to the submission\ndirectory for safe keeping. The individual steps are highlighted by\ncomments starting with a \u201c#\u201d. These comment lines can be kept in the\nfile.\n\n\nThis is the Lunarc standard example and represents \nrecommended\npractise\n for a basic serial job. You need to customise the file to\nsuit your specific needs. The script is suitable for jobs consuming no\nmore than 2000 MB of main memory.\n\n\n#!/bin/bash\n#\n# job time, change for what your job requires\n#SBATCH -t 00:10:00\n#\n# job name\n#SBATCH -J data_process\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o process_%j.out\n#SBATCH -e process_%j.err\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# copy the input data and program to node local disk\n# customise for your input file(s) and program name\ncp -p input.dat processor $SNIC_TMP\n\n# change to the execution directory\ncd $SNIC_TMP\n\n# run the program\n# customise for your program name and add arguments if required\n./processor\n\n# rescue the results to the submission directory\n# customise for your result file(s)\ncp -p result.dat $SLURM_SUBMIT_DIR\n\n\n\n\nWe recommend to be selective about the files you copy between the\nsubmission directory and the local node disk. If you have multiple input\nand result files you need to modify the copy statements accordingly. The\nabove example assumes your program has been compiled with the GCC\ncompiler loaded by default. If it has been compiled with a different\ncompiler you need to load the compiler module by adding a line similar\nto\n\n\nmodule add intel/12.1\n\n\n\nIf you are running on Erik, it is necessary to add the support for the\nGPU with the line\n\n\nmodule add cuda\n\n\n\nprior to the line ./processor. You need to consult with the person who\nbuild the executable for you. Lunarc provided modules typically complain\nif the wrong compiler is loaded and are hence self-documenting.\n\n\nVersion for codes requiring more memory than 2000 MB\n\n\nIf your program requires more memory than 2000 MB, use the following\nscript. This example is set up to use 4000 MB. If you need even more you\ncan request this, but your runs will be charged to your project at a\nhigher rate, since other cores have to remain idle. The comments on the\nprevious example also apply here\n\n\n#!/bin/bash\n#\n# job time, change for what your job requires\n#SBATCH -t 00:10:00\n#\n# job name\n#SBATCH -J data_process\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o process_%j.out\n#SBATCH -e process_%j.err\n#\n# requesting a large memory node and 4000 MB or main memory\n#SBATCH -C mem64GB\n#SBATCH --mem-per-cpu=4000\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# copy the input data and program to node local disk\n# customise for your input file(s) and program name\ncp -p input.dat processor $SNIC_TMP\n\n# change to the execution directory\ncd $SNIC_TMP\n\n# run the program\n# customise for your program name and add arguments if required\n./processor\n\n# rescue the results to the submission directory\n# customise for your result file(s)\ncp -p result.dat $SLURM_SUBMIT_DIR\n\n\n\n\nSince fewer nodes are equipped with 64 GB of memory, you have to allow\nfor longer queueing times until resource become available.\n\n\nRunning multiple serial jobs within a single job submission\n\n\nWhen you need to run many serial jobs, similar to the ones \ndescribed\nabove\n, these should be bundled together and\nsubmitted to the job queue in a small number of submissions or even a\nsingle submission. With SLURM is perfectly reasonable to run several\nhundred individual jobs in a single submission. To speed up the\nprocessing of your jobs, you can ask for the cores from a number of\nnodes. The concept is known as a \ntask-farm\n. The individual job are\nknown as \njob-steps\n.\n\n\nThe following is an example processing 200 such jobs using 16 cores from\na single node. The scripting use two scripts, the master script and the\nworker script. The Master script requests the resources (number of\ncores, job time, ...) and then registers 200 copies of the worker script\nwith SLURM using the command srun. The worker script is a modification\nof the \nbasic script\n described above.\n\n\nIn our example this will then start sixteen jobs on the sixteen cores\nyou requested. Once a job has finished, it will take an unprocessed job\nand place it on the idle core for processing. This will continue until\nall jobs are processed. The ordering of the jobs can not be relied on.\n\n\nFor our example the entire setup assumes the submission directory has\n200 sub-directories, named job_0, job_1, job_2, \u2026, job_199. Each of\nthe directories contains the input data and the program executable to be\nrun.\n\n\nKeep the number of jobs-steps at a reasonable level. Recent testing by\nthe Lunarc support team has shown that, when including a sleep statement\ninside the do loop the setup can be used to processes 800 jobs.\n\n\nThe master script\n\n\nThe master script describes the resources required and registers, once\nrunning the worker tasks with SLURM. In most cases modifying the number\nof cores needed, the total job time and the number of jobs to be\nprocessed should be all that is required.\n\n\n#!/bin/sh\n# requesting the number of cores needed\n#SBATCH -N 1\n#SBATCH --tasks-per-node=16\n#SBATCH --exclusive\n#\n# job time, change for what your job farm requires\n#SBATCH -t 20:00:00\n#\n# job name and output file names\n#SBATCH -J jobFarm\n#SBATCH -o res_jobFarm_%j.out\n#SBATCH -e res_jobFarm_%j.out\ncat $0\n\n# set the number of jobs - change for your requirements\nexport NB_of_jobs=200\n\n# Loop over the job number\n\nfor ((i=0; i\n$NB_of_jobs; i++))\ndo\n    srun -Q --exclusive -n 1 -N 1 \n        workScript.sh $i \n worker_${SLURM_JOB_ID}_${i} \n\n    sleep 1\ndone\n\n# keep the wait statement, it is important!\n\nwait\n\n\n\n\nThe script assumes that the job is described in a script file\n\u201cworkScript.sh\u201d, which takes a single number identifying the job\ndirectory to be accessed as a command line argument. Please note the\n\u201csleep 1\u201d command inside the do loop. In our testing this greatly\nenhances the stability by submitting the actual jobs over a longer\nperiod of time. With this statement included the script was able to\nsuccessfully handle up to about 800 outstanding jobs on 16 and 32 cores.\nFor reasons of job reliability, we therefore recommend not to process\nmore than 800 jobs in a single script. However it is possible to process\nsignificantly larger job numbers than 800 by carefully tuning sleep-time\nand core count in relation to the average job-time.\n\n\nRemarks:\n When using srun inside a batch script many srun-options act\ndifferently compared to using srun within a different environment.\nConsult the man-page of srun for documentation and contact the Lunarc\nhelp desk if your require further consultancy.\n\n\nThe worker script\n\n\nThis outlines the worker script. Compared to the script describing a\n\nsingle serial job\n, a few modifications are\nrequired:\n\n\n\n\n\n\nTo avoid access conflicts between the individual jobs, each job\n    \n creates a job private sub-directory on the node local disk.\n\n\n\n\n\n\nThe input file(s) are expected in the sub_directories job_0,\n    \n job_1, job_2, \u2026 of the submission directory. The result file(s)\n    \n will also be placed in these directories.\n\n\n\n\n\n\nThe example assumes a single input file and single result file. If\n    \n you have multiple input and/or result files modifications are\n    \n needed, as are modifications for that actual names of your file\n\n\n\n\n\n\nThe present set up allows for different executables for each\n    \n job-stop. The script assumes to find an executable named\n    \n \u201cprocessor\u201d in the same location as the input file(s). If you all\n    \n job steps use the same executable the scripts can be simplified.\n\n\n\n\n\n\nOnce a job-step has finished and the result file has been copied\n    \n back, the job private sub-directory on the node local disk is\n    \n removed to prevent the disc from overflow.\n\n\n\n\n\n\nIf you are using the above master script, the script should be named\n\u201cworkScript.sh\u201d.\n\n\n#!/bin/sh\n# document this script to stdout (assumes redirection from caller)\ncat $0\n\n# receive my worker number\nexport WRK_NB=$1\n\n# create worker-private subdirectory in $SNIC_TMP\nexport WRK_DIR=$SNIC_TMP/WRK_${WRK_NB}\nmkdir $WRK_DIR\n\n# create a variable to address the \njob directory\n\nexport JOB_DIR=$SLURM_SUBMIT_DIR/job_${WRK_NB}\n\n# now copy the input data and program from there\n\ncd $JOB_DIR\n\ncp -p input.dat processor $WRK_DIR\n\n# change to the execution directory\n\ncd $WRK_DIR\n\n# run the program\n\n./processor\n\n# rescue the results back to job directory\n\ncp -p result.dat ${JOB_DIR}\n\n# clean up the local disk and remove the worker-private directory\n\ncd $SNIC_TMP\n\nrm -rf WRK_${WRK_NB}\n\n\n\n\nMonitoring the progress of your multi-job submission\n\n\nUsing the -s option of sbatch you can monitor the progression of the\nindividual job-steps of your multi-job submission. Please keep in mind,\nthat the step number SLURM assigns to your job and the one you assign\ntypically differs from the loop index used in the master script.\n\n\nThe below is an output from squeue when running a script processing 500\njobs on 32 cores. The jobid of the job is 8070. The output shows the\njob-steps the script is presently processing\n\n\n[fred@alarik MultiSerialTest]$ squeue -j 8070 -s\nSTEPID NAME PARTITION USER TIME NODELIST\n8070.130 small_ex snic fred 2:09 an074\n8070.133 small_ex snic fred 2:02 an073\n8070.135 small_ex snic fred 1:55 an074\n8070.136 small_ex snic fred 1:41 an073\n8070.139 small_ex snic fred 1:41 an073\n8070.140 small_ex snic fred 1:41 an073\n8070.143 small_ex snic fred 1:41 an073\n8070.144 small_ex snic fred 1:41 an074\n8070.147 small_ex snic fred 1:41 an074\n8070.148 small_ex snic fred 1:41 an074\n8070.151 small_ex snic fred 1:41 an074\n8070.155 small_ex snic fred 1:38 an074\n8070.156 small_ex snic fred 1:35 an074\n8070.157 small_ex snic fred 1:34 an073\n8070.158 small_ex snic fred 1:34 an073\n8070.159 small_ex snic fred 1:34 an073\n8070.161 small_ex snic fred 1:34 an073\n8070.164 small_ex snic fred 1:33 an074\n8070.165 small_ex snic fred 1:33 an074\n8070.168 small_ex snic fred 1:32 an073\n8070.170 small_ex snic fred 1:26 an073\n8070.171 small_ex snic fred 1:12 an073\n8070.172 small_ex snic fred 1:12 an073\n8070.175 small_ex snic fred 1:11 an074\n8070.176 small_ex snic fred 1:11 an074\n8070.179 small_ex snic fred 1:11 an074\n8070.184 small_ex snic fred 1:04 an074\n8070.185 small_ex snic fred 0:42 an073\n8070.190 small_ex snic fred 0:35 an073\n8070.193 small_ex snic fred 0:35 an074\n8070.194 small_ex snic fred 0:13 an073\n8070.195 small_ex snic fred 0:13 an074\n\n\n\nMPI job using 16 tasks per node\n\n\nMost MPI jobs achieve best cost efficiency when deploying 16 tasks per\nnode, that is one task per core. Benchmarking by the Lunarc team showed\nthat these jobs typically require binding to achieve good performance.\nThe binding offered by the OpenMPI library works satisfactory.\n\n\nThe resource request is very easy in this case. Ask for a number of\ncores equivalent to the number of tasks you want to run. We recommend\nusing the --exclusive option to avoid getting unrelated jobs placed on\nthe last node in case the number of cores requested doesn\u2019t divide by\nthe number of cores per node. The following is an example submission\nscript to run the MPI application simula_mpi with 64 tasks on 4 nodes.\nNotice you do not need to specify the node count.\n\n\n#!/bin/sh\n# requesting the number of cores needed on exclusive nodes\n#SBATCH -N 4\n#SBATCH --tasks-per-node=16\n#SBATCH --exclusive\n#\n# job time, change for what your job requires\n#SBATCH -t 0:30:0\n#\n# job name\n#SBATCH -J simula_n64\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o simula_n64_%j.out\n#SBATCH -e simula_n64_%j.out\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# Example assumes we need the intel runtime and OpenMPI library\n# customise for the libraries your executable needs\nmodule add intel/13.0\nmodule add openmpi/1.6.2/intel/13.0\n\n# Copying the executable onto the local disks of the nodes\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp -p simula_mpi $SNIC_TMP\n\n# Copy the input file onto the headnode - if your MPI program\n# reads from all tasks, you need to do the above srun construct\n# again\ncp -p input.dat $SNIC_TMP\n\n# change to local disk and start the mpi executable\ncd $SNIC_TMP\nmpirun -bind-to-core simula_mpi\n\n# Copy result files back - example assumes only task zero writes\n# if in your application result files are written on all nodes\n# you need to initiate a copy on each node via srun\n\ncp -p result.dat $SLURM_SUBMIT_DIR\n```bash\n\nThis script assumes you are using up to 2000 MB of memory per task. If\nyou need more, adding the two lines\n\n    #SBATCH -C mem64GB\n    #SBATCH --mem-per-cpu=4000\n\nto the script will allow for using up to 4000 MB. Since fewer nodes are\nequipped with 64 GB of memory, you have to allow for longer queueing\ntimes until resource become available.\n\n### Modifications required for file I/O on all nodes\n\nAs discussed in the comments of the sample script, the script assumes\nthat only MPI-task 0 on the head node reads the input file and writes to\nthe output file. If for your MPI application every MPI task reads the\ninput file(s), replace the line\n\n    cp -p input.dat $SNIC_TMP\n\nwith\n\n    srun -n $SLURM_NNODES -N $SLURM_NNODES cp -p input.dat $SNIC_TMP\n\nand the file gets copied onto the local disk of each node. Matters are\nslightly more complex, if your output is written from all tasks. We\nassume the output files can be wild-carded as result_*.dat. Copying\nthese files back to the submission directory can be achieved creating a\nscript, which is placed on all nodes and subsequently executed on all\nnodes. The following addition to the submission script will create the\nscript and place it on all your nodes\n\n```bash\ncat \nEOF \n copyfile.sh\n#!/bin/sh\ncp -p result*.dat $SLURM_SUBMIT_DIR\nEOF\n\nchmod u+x copyfile.sh\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp copyfile.sh $SNIC_TMP\n\n\n\n\nThis needs inserting into the script before the \u201ccd $SNIC_TMP\u201d\nstatement. Once this is in place you can copy your result files by\nreplacing the line\n\n\ncp -p result.dat $SLURM_SUBMIT_DIR\n\n\n\nwith the line\n\n\nsrun -n $SLURM_NNODES -N $SLURM_NNODES copyfile.sh\n\n\n\nMPI jobs using fewer than 16 tasks per node\n\n\nIf you want to use fewer than 16 task per nodes to e.g. give more\nresources to the individual task, you can use the -N and --task-per-node\noptions of sbatch. We recommend not to use the -n option in this case.\nThis example is for 4 nodes with 8 tasks each, a total of 32 tasks. In\nour experience, in this case and when using --exclusive it is typically\nadvantageous to not use binding. Though we encourage experimenting with\nyour own application.\n\n\n#!/bin/sh\n# requesting the number of nodes and cores needed, exclusive nodes\n#SBATCH -N 4\n#SBATCH --tasks-per-node=8\n#SBATCH --mem-per-cpu=8000\n#SBATCH -C mem64GB\n#SBATCH --exclusive\n#\n# job time, change for what your job requires\n#SBATCH -t 0:30:0\n#\n# job name\n#SBATCH -J simula_n64\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o simula_n64_%j.out\n#SBATCH -e simula_n64_%j.out\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# Example assumes we need the intel runtime and OpenMPI library\n# customise for the libraries your executable needs\nmodule add intel/13.0\nmodule add openmpi/1.6.2/intel/13.0\n\n# Copying the executable onto the local disks of the nodes\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp -p simula_mpi $SNIC_TMP\n\n# Copy the input file onto the headnode - if your MPI program\n# reads from all tasks, you need to do the above srun construct\n# again\ncp -p input.dat $SNIC_TMP\n\n# change to local disk and start the mpi executable\ncd $SNIC_TMP\nmpirun simula_mpi\n\n# Copy result files back - example assumes only task zero writes\n# if in your application result files are written on all nodes\n# you need to initiate a copy on each node via srun\n\ncp -p result.dat $SLURM_SUBMIT_DIR\n\n\n\n\nOpenMP jobs using shared memory\n\n\nTo run a shared memory code using OpenMP on Alarik, you specify the\nnumber of cores you require using --tasks-per-node option of sbatch. In\nthis case you have to request placement on a single node with the \u201c-N 1\u201d\noption. In this example we call the executable \u201cprocessor_omp\u201d to\nemphasis that this need to be compiled with OpenMP support. Unless you\nare doing something special, you are not required to specify the\nenvironment variable OMP_NUM_THREADS. The example script uses the\ntechniques described for the \nbasic run script\n to\nengage the node local disk.\n\n\n#!/bin/bash\n#\n# Specify the number of threads - request all on 1 node\n#SBATCH -N 1\n#SBATCH --tasks-per-node=16\n#\n# job time, change for what your job requires\n#SBATCH -t 00:10:00\n#\n# job name\n#SBATCH -J data_process\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o process_omp_%j.out\n#SBATCH -e process_omp_%j.err\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# copy the input data and program to node local disk\n# customise for your input file(s) and program name\ncp -p input.dat processor_omp $SNIC_TMP\n\n# change to the execution directory\ncd $SNIC_TMP\n\n# run the program\n# customise for your program name and add arguments if required\n./processor_omp\n\n# rescue the results to the submission directory\n# customise for your result file(s)\ncp -p result.dat $SLURM_SUBMIT_DIR\n\n\n\n\nThis script allows to use 2000 MB of main memory per requested core. If\nyou need more memory, this can be requested by:\n\n\n#SBATCH -C mem64GB\n#SBATCH --mem-per-cpu=4000\n\n\n\nThis will increase you memory request to 4000 MB per requested core.\n\n\nThread binding for OpenMP codes\n\n\nThe Alarik nodes deploy a cache-coherent non-uniform-memory access\narchitecture (cc-numa). Many scientific simulation codes gain\nsignificant performance benefits on a cc-numa architecture when the user\nbinds the threads to physical cores of the hardware. This inhibits\nthread migration and improves memory locality. Unfortunately invoking\nthread binding is not standartised. Depending on the OpenMP runtime\nlibrary the user needs to modify different environment variables to bind\nhis threads.\n\n\nThread binding with the GNU compilers\n\n\nBy default the GNU compiler suite (gcc/gfortran) does not bind threads\nto cores. To engage thread binding, you need to set the environment\nvariable GOMP_CPU_AFFINITY and provide this with a binding list. When\nsetting\n\n\nexport GOMP_CPU_AFFINITY=\u201d0-15\u201d\n\n\n\nin your submission script, prior to starting your OpenMP application,\nthis will bind the threads to the 16 cores in the node. The above will\nbind thread 0 to core 0, thread 1 to core 1 and so on.\n\n\nMore advanced remark:\n If you want to utilise only 8 cores from a\nnode and asking for exclusive node access (#SBATCH --exclusive), it\nmight be a good idea to place threads on every second core only. This\nwill give you more memory bandwidth and make sure you are utilising all\nFPUs of the Interlagos architecture. This can be achieved by setting:\n\n\nexport GOMP_CPU_AFFINITY=\u201d0-14:2\u201d\n\n\n\nor\n\n\nexport GOMP_CPU_AFFINITY=\u201d0 2 4 6 8 10 12 14\u201d\n\n\n\nIt depend on details of your application, whether or not this helps\nperformance. Also note, when asking for a exclusive access to a note,\nyou will be charged for the full node, whether or not you use all cores.\n\n\nImportant pitfall:\n If you set GOMP_CPU_AFFINITY=0 this will bind\nall threads to core 0. You will see extremely poor performance in this\ncase.\n\n\nThread binding with the open64 compiler\n\n\nOpenMP code compiled with the \nopen64\n compiler will use thread\nbinding on Alarik. In standard use cases this will actually boost\nperformance. However in special situation, e.g. when using fewer threads\nthan the size of your partition, you might see a performance boost by\nnot using thread binding. To do so you need to set the environment\nvariable \u201cO64_OMP_SET_AFFINITY=false\u201d\n\n\nThread binding with the Intel compiler\n\n\nVersions 12.1 and 13.0 of the \nIntel\n compiler do not support thread\nbinding when used on the AMD processors deployed on Alarik. Starting\nfrom version 13.1 the Intel compile does support thread binding on the\nAMD processors deployed on Alarik. Obviously all versions of the Intel\ncompiler support thread binding on the Intel processors deployed on\nErik.\n\n\nFor version 13.1 of the Intel compiler thread is controlled by setting\nthe environment variable KMP_AFFINITY. The value\n\n\nexport KMP_AFFINITY=granularity=fine,compact\n\n\n\nmight be a good starting point for your experimentation.\n\n\nHybrid-jobs using threads within an MPI framework\n\n\nA cluster with multicore nodes such as Alarik is a natural environment\nto execute parallel codes deploying both MPI and OpenMP threads. When\nrunning such applications the optimal number of MPI-tasks and OpenMP\nthreads to place on a node can depend highly on the details of the\napplication. In particular for application which make many references to\nmain memory and the programmer has not implemented a proper \u201cfirst touch\ndata allocation\u201d it is typically \nbest to have 2 or 4 threads\n per MPI\ntask on an Alarik node. Together with a proper binding of your MPI tasks\nto the \u201cnuma-islands\u201d, this will ensure memory locality for your code.\nFor the below syntax you have to use \nversion 1.8.3 or newer\n of the\nOpenMPI library.\n\n\nIn the following we give a simple example script to run a MPI-OpenMP\nhybrid named simul_hyb on 2 nodes using 8 tasks and 4 threads per task.\nThe tasks and their threads will be bound to the \nnuma-islands\n,\nminimising cc-numa effects.\n\n\n#!/bin/sh\n# requesting number of nodes (-N option)\n# number of mpi-tasks per node\n# and number of threads per task exclusive nodes\n#SBATCH -N 2\n#SBATCH --tasks-per-node=4\n#SBATCH --cpus-per-task=4\n#SBATCH --exclusive\n# time required\n#SBATCH -t 01:00:00\n#SBATCH -J hybrid_run\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o simula_N2t4c4_%j.out\n#SBATCH -e simula_N2t4c4_%j.out\n\ncat $0\n\n# Example assumes we need the intel runtime and OpenMPI library\n# customise for the libraries your executable needs\nmodule add intel/15.0\nmodule add openmpi/1.8.3/intel/15.0\n\n# Copying the executable onto the local disks of the nodes\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp -p simul_hyb $SNIC_TMP\n\n# Copy the input file onto the headnode - if your MPI program\n# reads from all tasks, you need to do the above srun construct\n# again\ncp -p input.dat $SNIC_TMP\ncd $SNIC_TMP\n\n# setting number of OpenMP threads and ask for thread binding\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nexport OMP_PROC_BIND=true\n\nmpiexec --map-by ppr:$SLURM_NTASKS_PER_NODE:node:PE=$SLURM_CPUS_PER_TASK simul_hyb\n\n# Copy result files back - example assumes only task zero writes\n# if in your application result files are written on all nodes\n# you need to initiate a copy on each node via srun\ncp -p result.dat $SLURM_SUBMIT_DIR\n\n\n\n\nThe example assumes that MPI task 0 is the only task reading and writing\ninput files. If your application reads and writes data on all nodes, you\nneed to study the \nmodifications\n described in the\nMPI section.\n\n\nAs discussed, the above binds the tasks and their threads to the\nnuma-islands of the Alarik architecture. Alariks numa-islands have four\ncores, therefore the script is best used with 2 or four threads per MPI\ntask. This results in one or two MPI tasks per numa islands.\n\n\nThings to try for MPI-OpenMP hybrids with 16 threads per task\n\n\nWhile using more than 4 threads per MPI task on the Alarik system can\nresult in reduced performance due to cc-numa effects, there are\nsituations when using 16 threads per task can be required (e.g. special\nalgorithms or extreme memory requirements per MPI task).\n\n\nWhen running 16 threads per MPI task, that is a single MPI task per\nAlarik node, you might want to experiment with starting your job without\nspecifying binding on mpiexec, that is remove the -bind-to-core, but\nutilise the \nOpenMP thread binding\n techniques\ndescribed in the OpenMP sample section.\n\n\nInteractive access to compute nodes\n\n\nSometimes it is desirable to have an interactive login to the compute\nnodes of the cluster. Extensive code testing is a typical use case.\n\n\nStarting an interactive session\n\n\nTo start an interactive session you need to use the \u201cinteractive\u201d\ncommand. This will request the required resources from the resource pool\nfor you and start the interactive session once the resources are\navailable.\n\n\nUse the following command to start an interactive session asking for 32\ncores lasting 60 minutes\n\n\ninteractive -n 32 -t 60\n\n\n\nOn Alarik and Eric this will be allocated on multiple nodes, since the\nnodes have only 16 cores available. The interactive session will last\nuntil either the requested time, 60 minutes in the above example, has\nexpired or you manually exit the interactive shell. Your account gets\ncharged with the wall time duration of your interactive session,\nindependent of the amount of computation you do. In the above example,\nif your session lasts until it expires after 60 min, you get charged for\n32 cpu hours. If you terminate your session after 1/2 hour, you would\nget charged 16 cpu hours.\n\n\nThe interactive command supports most command line options of the sbatch\ncommand. Please refer to the man pages of sbatch.\n\n\nModules and environment variables\n\n\nLoaded modules and environment are not always exported properly to your\ninteractive session. Once placed in the interactive session, we\nrecommend users to reload \nall\n the modules they require. That is\ndespite the \u201cmodules list\u201d command claiming they are still loaded.\n\n\nYou also need to check whether environment variables still have the\nrequired values. If the software you are using has a set-up script, you\nmight need to re-run that script.\n\n\nKnown issues with the interactive command\n\n\nNone at the time of writing.", 
            "title": "Batch system"
        }, 
        {
            "location": "/batch_system/#slurm-the-batch-system-on-alarik-and-erik", 
            "text": "On a modern HPC system efficient management of the compute resources is\nabsolutely crucial for the system to perform. Alarik and Erik are the\nfirst Lunarc systems to deploy SLURM ( S imple  L inux  U tility\nfor  R esource  M anagement) as resource manager. For your program\nto be executed you have to describe to SLURM the resources required by\nyour program, the name of your program and the command line arguments\nyour program may require. SLURM also allows monitoring and manipulation\nof the progress of your programs execution.  This document contains two key parts. The  first\npart  describes in-depth the job submission system\nand its options. The  second part  gives example\nscripts for the most common use cases. They hopefully serve as a good\nstarting point when creating submission scripts fitting your needs and\nrequirements.", 
            "title": "SLURM - the batch system on Alarik and Erik"
        }, 
        {
            "location": "/batch_system/#job-submission", 
            "text": "", 
            "title": "Job submission"
        }, 
        {
            "location": "/batch_system/#first-example-for-a-job-submission", 
            "text": "The job script and sbatch  You register your program with SLURM for execution using the  sbatch \ncommand. This is done easiest by using a  job description file . The job\ndescription file is also know as a  job script .  A very simple job script, looks as follows:  #!/bin/sh\n#SBATCH -t 00:05:00\n\necho \"hello\"  Write this into a file. In the following we assume the file is named\necho_script.sh, but in principle any name will do. You can now send the\nscript for execution using the sbatch command. This will execute the\n\u201cprogram\u201d echo on the backend.  sbatch echo_script.sh  This should deliver a screen output similar to  [fred@alarik Serial]$ sbatch echo_script.sh\nSubmitted batch job 7185  Where 7185 is the job number assigned by SLURM. Once your job has\nexecuted you will find a file slurm-7185.out in your directory which\ncontains the output and error messages from your program.  The three parts of a job script  The example echo_script.sh shows the three parts every job script\nrequires   Shell specification  Resource statement  Body containing a UNIX script   In our example each part consists of a single line. The first line of\nour example contains the shell specification, in most cases the sh-shell\nas used here is just fine. The second line starting with #SBATCH\nspecifies the resources needed. In our case it asks for 10 minutes of\ncomputer time. If the jobs hasn\u2019t finished after that time, SLURM will\nterminate it. Job scripts typically contain more than one of these\nstatements, specifying e.g. more than one processor or more memory. The\nmost commonly used resource statements at Lunarc will be explained\nbelow. The resource statements are followed by a list of programs and\nUNIX commands to be executed on the system. This is actually a normal\nUNIX script and everything you can do in a UNIX script can be done here\nas well. In our example the script consists out of the UNIX echo\ncommand.", 
            "title": "First example for a job submission"
        }, 
        {
            "location": "/batch_system/#resource-statements-for-all-jobs", 
            "text": "We now describe a number of statements which are most commonly used to\nspecify resource requirements for all kind of jobs. Refer to \u201cman\nsbatch\u201d for more information.  Walltime  The walltime attribute specifies the time requested for completing the\njob. The time is  not  cpu-time but the total time, as measured by a\nnormal clock. In the previous example the time requested was 0 hours 5\nminutes and 0 seconds. Walltime is specified in seconds or using the\nfollowing notation:  Hours:Minutes:Seconds  If your calculation hasn\u2019t finished once the specified time has elapsed,\nSLURM will terminate your job. It is therefore  good practise  to\nspecify a bit more time than you anticipate your job to take. This makes\nsure that you still get your results, even the jobs is slowed by some\ninterference, e.g. waiting for a write to a shared file system to\nfinish. However don\u2019t specify excessive extra time. Due to scheduling\nconstraints, jobs asking for less time will typically spend less time in\nthe queue, waiting for their execution. This also provides safety\nagainst depletion of your allocation. If, e.g., your job hangs, SLURM\nwill terminate your job and the project will be charged less time if the\nwalltime margin is not excessive.  To specify your walltime requirements write a statement like  #SBATCH -t 00:10:00  into your job script.  The maximum walltime for any job on Alarik is 168h, which is the same as\n7 days. On Erik the maximum walltime for any job is 48h.  Job naming  All jobs are given both a job identifier and a name, for easier\nidentification in the batch-system. The default name given to a job is\nthe file name of the submit script, which can make it difficult to\nidentify your job, if you use a standard name for your submit scripts.\nYou can give your job a name from inside the script by using the -J\noption:  #SBATCH -J parameterTest  This will name your job \u201cparameterTest\u201d.  Specifying a project for users with multiple projects  Most users are members of only one project. These users do not need to\nspecify a project in their in their submission script. The Lunarc set-up\nwill automatically use that project for accounting.  A few users are members of more than project. In this case the system\nwould not know which project to charge for the run, so you need to\nspecify the project using the -A option:  #SBATCH -A snic2015-x-xxx  Replace the \u201csnic2015-x-xxx\u201d with the string naming your project. You\ncan inquire the correct string using the projinfo command or the SUPR\nsystem.  Specifying memory requirements  Alarik has 32 GB of memory installed on the small memory nodes and 64 GB\nof memory on the large memory nodes. The default memory request per core\non the system is 2000 MB (a sixteenth of 32GB). If more then 2000 MB per\ncore is needed it has to be requested explictly with the --mem-per-cpu  option of sbatch. In this case you also have to\nrequest allocation on a large memory node using the  -C mem64GB \noption of sbatch. The following show an example how to request 4000 MB\nor main memory per compute core used:  #SBATCH -C mem64GB\n#SBATCH --mem-per-cpu=4000  When requesting more than 2000 MB of memory, your jobs may spend a\nlonger time in the queue, waiting for execution, since it needs to wait\nfor run-slot(s) on the large memory nodes to become available. When\nrequesting more then 4000 MB per processing core, your jobs will be\ncharged at a higher rate. In this case some processing cores have to\nremain idle since you are using more than your fair share of memory.  Erik has 64 Gb of memory on the standard nodes. Each node has two CPUs\nwith eight cores each. The default memory request per core is therefore\n4000 MB of memory. As in the case of Alarik, if more than 4000MB of\nmemory per core is needed it has to be described as above.  Controlling job output  By default, the output which your job writes to stdout and stderr is\nwritten to a file named  slurm_%j.out  The %j in the file name will be replaced by the jobnumber SLURM assigns\nto your job. This ensures that the output file from your job is unique\nand different jobs do not interfere with each other's output file.  In many cases the default file name is not convenient. You might want to\nhave a file name which is more descriptive of the job that is actually\nrunning - you might even want to include important meta-data, such as\nphysical parameters, into the output filename(s). This can be achieved\nby using the -o and -e options of sbatch. The -o option specifies the\nfile containing the stdout and the -e option the file containing the\nstderr. It is good practise to include the %j string into the filenames.\nThat will prevent jobs from overwriting each other's output files. The\nfollowing gives an example:  #SBATCH -o calcflow_m1_%j.out\n#SBATCH -e calcflow_m1_%j.err  You can give the same filename for both options to get stdout and stderr\nwritten to the same file.  Notification  SLURM on the systems can send you email if the status of your job\nchanges as it progresses through the job queue. To use this feature you\nneed to specify the email address using the --mail-user option and\nspecify the event you want to get notified about using the --mail-type\noption. The following  #SBATCH --mail-user=fred@institute.se\n#SBATCH --mail-type=END  Will send an email to the address fred@institute.se once the job has\nended. Valid type values, selecting the event you can get notified\nabout, are BEGIN, END, FAIL, REQUEUE, and ALL (any state change).  Job dependencies  To describe job dependencies, use the -d option of sbatch. This is\nparticularly useful for job dependencies, in workflows.  To illustrate this consider the following example. You require a serial\njob to create a mesh for your simulation. Once this has finished, you\nwant to start a parallel job, which uses the mesh. You first submit the\nmesh creation job using sbatch  [fred@alarik Simcode]$ sbatch run_mesh.sh\nSubmitted batch job 8042  As discussed, sbatch returns you a jobid, 8042 in this example. You use\nthis to declare your dependency when submitting the simulation job to\nthe queue  [fred@alarik Simcode]$ sbatch -d afterok:8042 run_sim.sh\nSubmitted batch job 8043  When using squeue to monitor job 8043, this should now be in status\npending (PD) with the reason of dependency. Another common use case for\nthis functionality is a simulation requiring many days of computer times\nbeing split into a number of submissions.  Test queue  To run short tests, it is possible to request extra high priority on\nAlarik with the help of  #SBATCH --qos=test  For one such job, the maximum walltime is 1 h and the maximum number of\nnodes is two and a user is only allowed to run two such jobs\nsimultaneously. A system of floating reservations is used to free two\nnodes every second hour between 8.00 and 20.00 to reduce the queue time\nfor test jobs. The way it works also means that the shorter the test\njob, the more likely it is to start sooner rather than later. It is not\nallowed to use qos=test for series of production runs.  On Erik there is one two-GPU node reserved for tests in a partition of\nits own, which is specified with  #SBATCH -p test  Like on Alarik, the maximum walltime is 1 h.  Extra fat nodes on Alarik  Alarik has four nodes with 48 cores and 128 GB memory. To access them,\nthe partition extra has to be specified  #SBATCH -p extra  Furthermore, the amount of memory per requested core also needs to be\ngiven.  #SBATCH --mem-per-cpu= memory in MB   Otherwise, the default value of 2 000 MB will be set at and if more is\nused, slurm can kill the job. For example, to run on the 48 cores of a\nsingle node and use a total of 128 000 MB of memory (for more on\nmultiprocessor statements, see the next section):  #SBATCH -N 1\n#SBATCH --tasks-per-node=48\n#SBATCH --mem-per-cpu=3000\n#SBATCH -p extra  Fat, extra fat and MIC nodes on Erik  Erik has 7 nodes with 4 GPUs (and 96 GB of memory). To access them, the\npartition fat has to be specified  #SBATCH -p fat  One node is equipped with 8 GPUs (and 96 GB of memory), which is in\npartition extra  #SBATCH -p extra  There is also one node with two Xeon Phi (MIC) cards in the partition\nmic  #SBATCH -p mic  There is also one node with two Nvidia K80 cards in the partition new  #SBATCH -p new  If no -p option is specified, normal nodes with two Nvidia K20 cards\nwill be allocated to the job.", 
            "title": "Resource statements for all jobs"
        }, 
        {
            "location": "/batch_system/#resource-statements-for-multiprocessor", 
            "text": "In HPC it is very common to have many processing elements working on a\njob. The extra processing power can be utilised to process large\nproblems beyond the capabilities of a single processing element. It can\nalso be used to swiftly perform a number of calculations within a single\njob submission.  Terminology around nodes, processors, cores, tasks  There is a a lot of structure within modern HPC equipment. For the\npurposes of this user guide we will stick to the following terminology:     Term  Explanation  Number on Alarik  Number  on Erik      Node  A physical computer  Standard:  Standard:      200  16            Extra:  Fat:      4  7             Extra:       1             Mic:       1             New:       1    Processor  This denotes a the multi-core processor, housing many processing elements  Standard:  2 per node      2 per node             Extra:       4 per node     GPU  This denotes a nvidia co-processor  0  Standard:       2 per node             Fat:       4 per node             Extra:       8 per node             Mic:       0 per node             New:       2 cards per node       2 logical per card       4 logical per node    Socket  This is the \u201cplug\u201d the processor gets plugged into.  Used as a synonym for the processor  Standard:  2 per node      2 per node             Extra:       4 per node     Core  Individual processing element  Standard:  16 per node      16 per node  8 per processor      8 per processor             Extra:       48 per node       12 per processor     Task  This is a software concept.  It denotes a process, which is an instance of a running program.  It has its own data and instruction stream(s).  It can fork multiple threads to increase the computational speed.  Serial programs and pure MPI programs do not spawn threads.  User controls in job script  User controls in job script    Thread  This is also a software concept.  A thread is a stream of instructions executed on the hardware.  It is part of a task and shares resources such as  data with other threads within the same task.  User controls in job script  User controls in job script     Outline: Resource requests for multiprocessor jobs  When running multi processor jobs on the Lunarc clusters, one should\nspecify:   The number of nodes required by the jobs  The number of computational tasks per node  The number of threads spawned by each task   For a pure MPI job or when processing a large number of serial jobs in a\nso called task farm, one will typically only specify the items 1 and 2,\nwhile for a threaded job, using e.g. OpenMP or Java, one will typically\nonly specify items 1 and 3.  It is typically not advisable to have the product of items 2 and 3\nexceeding the number of cores per node, which is 16 for standard Alarik\nand Erik compute nodes. On the Alarik extra compute nodes this number is\n48. In most cases users requesting multiple nodes will want the product\nto equal the number of cores per node. The syntax how to control nodes,\ntasks per node and threads per task is explaned below.  Exclusive node access  For parallel codes using MPI or OpenMP it is typically best to keep\ninterference on the nodes at a minimum, that is to have exclusive access\nto the nodes you are using. This also applies to specialist and\nexperimental work, which would interfere very badly with other user\u2019s\ncodes on the nodes. Adding  #SBATCH --exclusive  to your job script will ensure that SLURM will allocate dedicated nodes\nto your job. Obviously your project gets charged for the full costs of\nthe nodes you are using, that is in case of Alarik and Erik 16 cores per\nnode.  Specifying the number of nodes required for the job  In SLURM one requests the number of nodes for a job with the  -N \noption. The following statement requests four nodes for your job:  #SBATCH -N 4  Important:  without using either the --tasks-per-node or\nthe --cpus-per-task options of sbatch, this will reserve a single core\nper node, so four in total, which is most likely not what you want.  Specifying the number of tasks per node  Use the --tasks-per-node of sbatch to specify the number of tasks you\nrequire per node. Most multinode job will set this equal to the number\nof cores availble per node. The following example asks for 16 task per\nnode:  #SBATCH --tasks-per-node=16  This should be used together with the -N option, specifying the number\nof nodes to be used. The default value for the number of tasks per node\nis 1. For example to specify the requirements for an MPI job with 64\ntasks or multiprocessor job using 64 processors to process a larger\nnumber of serial jobs one would specify  #SBATCH -N 4\n#SBATCH --tasks-per-node=16  When using fewer than 16 tasks per node and you want to prevent other\nuser\u2019s jobs sharing your node, you need to consider using\nthe --exclusive option. If --exclusive is not specified, SLURM might\nplace other tasks onto your node.  Specifying the number of threads for a shared-memory job  If you want to run shared-memory applications using threads, e.g. OpenMP\nparallised code or Java applications, you need to specify the number of\nthreads you require per task. This can be done with the --tasks-per-node\noption of sbatch.  For a standard shared-memory program, which doesn\u2019t also use distributed\nmemory programming models such as MPI, one is restricted to a single\nnode. On that node, one can request as many threads as there are cores\non the node. On the standard Alarik compute nodes one can efficiently\nuse up to 16 threads. Use the following resource statement:  #SBATCH -N 1\n#SBATCH --tasks-per-node=16  If your program is only efficient at a lower thread count, you may want\nto use e.g.:  #SBATCH -N 1\n#SBATCH --tasks-per-node=4  if you only want to use four threads. The Alarik extra nodes with 48\ncores allow for very wide shared-memory jobs:  #SBATCH -N 1\n#SBATCH --tasks-per-node=48\n#SBATCH --mem-per-cpu=3000\n#SBATCH -p extra  Resource statements for hybrid programs using distributed and shared memory  So-called hybrid programs, using both distributed and shared-memory\ntechniques have recently become popular. For example: for a program\nusing 32 MPI tasks, each task spawning 2 OpenMP threads one would\nrequire 4 nodes and place eight tasks on each node. The number of\nthreads per task is given by --cpus-per-task. The resource statement\nwould look as follows:  #SBATCH -N 4\n#SBATCH --tasks-per-node=8\n#SBATCH --cpus-per-task=2  Specifying the number of cores to be required by the job  In special cases, such as using very unusal numbers of tasks, the  -n \noption of sbatch to specify the number of cores might become useful.\nWhen running a pure MPI program this option corresponds to the  number\nof tasks  required for your program. The following statement in a job\nscript would reserve 63 cores for your job  #SBATCH -N 4\n#SBATCH --tasks-per-node=16\n#SBATCH -n 63  Please consider using the --exclusive option of sbatch to avoid SLURM\nspreading your job on more nodes than necessary and placing other user\u2019s\njobs on nodes utilising fewer than 16 cores for your job. Other user\u2019s\njobs could via shared node resources (memory bus, cache, FPU, \u2026)\ninterfere with your job and introduce undue operational noise. Such\nnoise is something parallel program execution can be extremely sensitive\nto.", 
            "title": "Resource statements for multiprocessor"
        }, 
        {
            "location": "/batch_system/#program-execution-environment", 
            "text": "Job execution environment  When submitting your job to SLURM using sbatch, your entire environment\nincluding the currently loaded modules gets copied. This behaviour is\ndifferent from earlier Lunarc machines, including Platon. On Alarik,\nwhen hitting sbatch:   Make sure that the loaded modules and any environment variable you may have set will not be in conflict with the environment expected by the job script   Compiler modules  On Alarik we automatically load a modern version of the GCC compiler,\nwhich supports the deployed AMD Opteron processors. At the time of\nwriting this is version 4.6.2 of GCC. If you prefer using a different\ncompiler, you can add the desired module, e.g., version 12.1 of the\nIntel compiler  module add intel/12.1  If different modules have files with the same names in the search path,\nthose of the module added last will be picked. Generally this is not a\nproblem, but the compiler wrappers in the openmpi modules have the same\nnames and it safest to only have one loaded at a time.  On Erik the same compilers as on Alarik are present. Note that the\nprocessors on Erik are of the Intel Xeon type and thus utilize the mkl\nas supplied.  SLURM variables  To come  SNIC variables  The SNIC meta-centres have agreed on a set of environment variables\nwhich should improve the portability of (parts of) job-scripts between\nSNIC sites. On Alarik the following variables are set by the system:   Environment variable     Explanation                                                                                 Value on Alarik     Value on Erik   SNIC_SITE                 Identifying the SNIC site you are using                                                       lunarc                lunarc  SNIC_RESOURCE             Identifying the compute resource you are using                                                alarik                erik  SNIC_BACKUP               User directory which is:                                                                      /home/         /home/                             Regularly backed up against accidental deletion\n\n                           Typically extremely limited space\n\n                           Use for e.g. precious source code  SNIC_NOBACKUP             User directory which is:                                                                      /lunarc               /lunarc                             Accessible on all Lunarc systems                                                            /nobackup             /nobackup\n\n                           Outliving individual systems                                                                /users/ user        /users/ user \n\n                           For storing larger amounts of data\n\n                           Not backed up against accidental deletion\n\n                           Protected against disk failure (RAID configuration)\n\n                           On Alarik: the primary root directory for job management (job scripts, input/output data)  SNIC_TMP                  Directory for best performance during a job                                                    jobid dependent       jobid dependent                           At Lunarc:\n\n                           Local disk on nodes\n\n                           Storing temporary data during job execution\n\n                           High bandwidth\n\n                           Automatically deleted\n\n                           Transfer data with long-term value to SNIC_NOBACKUP before job has finished", 
            "title": "Program execution environment"
        }, 
        {
            "location": "/batch_system/#using-the-node-local-disks-to-improve-io-performance", 
            "text": "On Alarik and Erik, all nodes have a local disk. This disk offers\nsuperior bandwidth when compared to accessing your home space or the\n/lunarc/nobackup centre storage. In particular when files are read or\nwritten repeatedly during execution it is advisable to copy the input\ndata onto the local disk prior to job execution and copy the result\nfiles back to the submission directory once your program has finished.\nDuring its execution, your program would then read and write to local\ndisk.  In case of Alarik and Erik, the submission directory typically resides\non the /lunarc/nobackup centre storage. All data left on the node local\ndisks  will be deleted  when your job has finished. You need to copy\neverything of interest to a more permanent storage space such as\n/lunarc/nobackup. If a job is terminated prematurely, for example, if it\nexceeds the requested walltime, the files on the local disk (in\n$SNIC_TMP) will be lost.  Files that would still be useful can be listed in a special file $SNIC_TMP/slurm_save_files . Filenames are assumed to be relative\nto $SNIC_TMP and should be separated by spaces or listed on separate\nlines. Wildcards are allowed. These files will be copied from the local\ndisk where $SNIC_TMP/slurm_save_files exists to the submission\ndirectory regardless whether the job ends as planned or is deleted,\nunless there is a problem with the disk or node itself. Note that the\nslurm_save_files feature is unique to Lunarc.  For the required UNIX scripting you should use the following environment\nvariables. Example scripts using this technique are provided in the\nexample section of this document. Contact the help desk if you have\nspecific requirements and require consultation.   Variable           Addressed Volume   SNIC_TMP            node local disk                     copy your input data here and start your program from here  TMPDIR               node local disk                     Many applications use this environment variable to locate a disk volume for temporary scratch space. If your application follows that convention nothing needs to be done.  SLURM_SUBMIT_DIR   submission directory                     where you ran sbatch", 
            "title": "Using the node local disks to improve I/O performance"
        }, 
        {
            "location": "/batch_system/#launching-mpi-jobs-in-openmpi", 
            "text": "To execute message passing parallel jobs these should be built against\none of the MPI libraries provided by the support team as a module. To\nexecute an MPI job, your job script should do the following   Load MPI module relevant for the compiler you are using  Start the program with mpirun  On Alarik the correct binding is crucial to achieve good\n      performance. When using 16 task per node, we recommend using\n      the -bind-to-core option of mpirun. When using fewer than 16 tasks\n      we recommend experimenting whether not using binding helps or\n      hinders performance.", 
            "title": "Launching MPI jobs in OpenMPI"
        }, 
        {
            "location": "/batch_system/#submitting-monitoring-and-manipulating-jobs-in-slurm", 
            "text": "Submitting with sbatch  One uses the command sbatch to submit a job script to the batch system\nfor execution. SLURM will reply with the jobid number. The job will then\nbe held in the queue until the requested resources become available. A\ntypical use case looks as follows:  [fred@alarik MPItest]$ sbatch runjob.sh\nSubmitted batch job 7197  User fred submitted the script runjob.sh to the job queue and got the\njobid 7197 assigned to it.  Starting executables within SLURM with srun  The command srun allows to start executables in a way managed by SLURM.\nThis is particularly effective if you want to process a large number of\njobs within a single submission to the batch system. A use case of srun\nto start many serial jobs in a single multicore submission scipt is\ndiscussed in the  example section .  Monitoring with squeue  The command squeue will show you the current state of the job queue. The\nstandard output, created by calling squeue without any options looks as\nfollows:  JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON)\n7303 snic hybrid_n fred PD 0:00 32 (Priority)\n7302 snic hybrid_n fred PD 0:00 32 (Priority)\n7301 snic hybrid_n fred PD 0:00 32 (Resources)\n7304 snic preproce karl PD 0:00 6 (Priority)\n7300 snic hybrid_n fred R 0:24 32 an[001-032]\n7305 snic preproce karl R 0:37 6 an[081-086]\n7306 snic hybrid_n fred R 0:37 6 an[081-086]\n7307 snic testsimu sven R 0:07 1 an081  The first column gives the jobid, the third the job names, followed by\nthe userid. The column labeled \u201cST\u201d gives the job state. The most\nimportant states are:   Symbol     Meaning    R          running   PD           pending, awaiting resources  CG           completing   The state column is followed by the time used by the job and number of\nnodes utilised by the job. For running jobs the last column gives the\nnames of the nodes utilised or if the job is waiting a reason why it is\nnot executing.  The squeue command is highly configurable. Useful options include -u\nmyid, which lists all jobs of the user myid and also the --start option.\nThe latter gives the current estimate of when SLURM expects the job to\nstart. Note, that this can shift in either direction, depending on e.g.\njobs finishing earlier than specified or jobs with higher priority\ngetting added to the job queue.  The command jobinfo is a script that sorts the output of squeue into\nrunning and waiting jobs. It also shows additional information, such as\nhow long running jobs have left and in some cases when waiting jobs are\nexpected to start.  Terminating jobs with scancel  It is frequently required to remove jobs from the queue. This might be\nthat you discover a problem in your job specification or intermediate\nresults of running job indicating that something went wrong. Use scancel\nto remove a job from the job queue. To do so you need the jobid, which\nis best queried with the squeue command. To remove the job with the\njobid 7103 from the job queue type  scancel 7103", 
            "title": "Submitting, monitoring and manipulating jobs in SLURM"
        }, 
        {
            "location": "/batch_system/#example-job-scripts", 
            "text": "In this section we provide sample scripts for typical use cases.", 
            "title": "Example job scripts"
        }, 
        {
            "location": "/batch_system/#job-scripts-using-the-node-local-disk", 
            "text": "Basic run script  As discussed the node local disk provides better I/O-bandwidth than the\nother file systems available on Alarik. The following script assumes the\nprogram processor reads the file  input.dat  and produces a file result.dat .  This example executes a single serial program and is suitable for the\noccasional serial job. If you need to process a large number of serial\njobs, we request you bundle them into a single submission. Refer to the\nsection \u201c R unning multiple serial jobs within a\nsingle job submission \u201d for a scripting example.  The script copies the input data and the program executable from the\nsubmission directory to the node local disk, executes the program on the\nnode local disk and copies the result file back to the submission\ndirectory for safe keeping. The individual steps are highlighted by\ncomments starting with a \u201c#\u201d. These comment lines can be kept in the\nfile.  This is the Lunarc standard example and represents  recommended\npractise  for a basic serial job. You need to customise the file to\nsuit your specific needs. The script is suitable for jobs consuming no\nmore than 2000 MB of main memory.  #!/bin/bash\n#\n# job time, change for what your job requires\n#SBATCH -t 00:10:00\n#\n# job name\n#SBATCH -J data_process\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o process_%j.out\n#SBATCH -e process_%j.err\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# copy the input data and program to node local disk\n# customise for your input file(s) and program name\ncp -p input.dat processor $SNIC_TMP\n\n# change to the execution directory\ncd $SNIC_TMP\n\n# run the program\n# customise for your program name and add arguments if required\n./processor\n\n# rescue the results to the submission directory\n# customise for your result file(s)\ncp -p result.dat $SLURM_SUBMIT_DIR  We recommend to be selective about the files you copy between the\nsubmission directory and the local node disk. If you have multiple input\nand result files you need to modify the copy statements accordingly. The\nabove example assumes your program has been compiled with the GCC\ncompiler loaded by default. If it has been compiled with a different\ncompiler you need to load the compiler module by adding a line similar\nto  module add intel/12.1  If you are running on Erik, it is necessary to add the support for the\nGPU with the line  module add cuda  prior to the line ./processor. You need to consult with the person who\nbuild the executable for you. Lunarc provided modules typically complain\nif the wrong compiler is loaded and are hence self-documenting.  Version for codes requiring more memory than 2000 MB  If your program requires more memory than 2000 MB, use the following\nscript. This example is set up to use 4000 MB. If you need even more you\ncan request this, but your runs will be charged to your project at a\nhigher rate, since other cores have to remain idle. The comments on the\nprevious example also apply here  #!/bin/bash\n#\n# job time, change for what your job requires\n#SBATCH -t 00:10:00\n#\n# job name\n#SBATCH -J data_process\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o process_%j.out\n#SBATCH -e process_%j.err\n#\n# requesting a large memory node and 4000 MB or main memory\n#SBATCH -C mem64GB\n#SBATCH --mem-per-cpu=4000\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# copy the input data and program to node local disk\n# customise for your input file(s) and program name\ncp -p input.dat processor $SNIC_TMP\n\n# change to the execution directory\ncd $SNIC_TMP\n\n# run the program\n# customise for your program name and add arguments if required\n./processor\n\n# rescue the results to the submission directory\n# customise for your result file(s)\ncp -p result.dat $SLURM_SUBMIT_DIR  Since fewer nodes are equipped with 64 GB of memory, you have to allow\nfor longer queueing times until resource become available.", 
            "title": "Job scripts using the node local disk"
        }, 
        {
            "location": "/batch_system/#running-multiple-serial-jobs-within-a-single-job-submission", 
            "text": "When you need to run many serial jobs, similar to the ones  described\nabove , these should be bundled together and\nsubmitted to the job queue in a small number of submissions or even a\nsingle submission. With SLURM is perfectly reasonable to run several\nhundred individual jobs in a single submission. To speed up the\nprocessing of your jobs, you can ask for the cores from a number of\nnodes. The concept is known as a  task-farm . The individual job are\nknown as  job-steps .  The following is an example processing 200 such jobs using 16 cores from\na single node. The scripting use two scripts, the master script and the\nworker script. The Master script requests the resources (number of\ncores, job time, ...) and then registers 200 copies of the worker script\nwith SLURM using the command srun. The worker script is a modification\nof the  basic script  described above.  In our example this will then start sixteen jobs on the sixteen cores\nyou requested. Once a job has finished, it will take an unprocessed job\nand place it on the idle core for processing. This will continue until\nall jobs are processed. The ordering of the jobs can not be relied on.  For our example the entire setup assumes the submission directory has\n200 sub-directories, named job_0, job_1, job_2, \u2026, job_199. Each of\nthe directories contains the input data and the program executable to be\nrun.  Keep the number of jobs-steps at a reasonable level. Recent testing by\nthe Lunarc support team has shown that, when including a sleep statement\ninside the do loop the setup can be used to processes 800 jobs.  The master script  The master script describes the resources required and registers, once\nrunning the worker tasks with SLURM. In most cases modifying the number\nof cores needed, the total job time and the number of jobs to be\nprocessed should be all that is required.  #!/bin/sh\n# requesting the number of cores needed\n#SBATCH -N 1\n#SBATCH --tasks-per-node=16\n#SBATCH --exclusive\n#\n# job time, change for what your job farm requires\n#SBATCH -t 20:00:00\n#\n# job name and output file names\n#SBATCH -J jobFarm\n#SBATCH -o res_jobFarm_%j.out\n#SBATCH -e res_jobFarm_%j.out\ncat $0\n\n# set the number of jobs - change for your requirements\nexport NB_of_jobs=200\n\n# Loop over the job number\n\nfor ((i=0; i $NB_of_jobs; i++))\ndo\n    srun -Q --exclusive -n 1 -N 1 \n        workScript.sh $i   worker_${SLURM_JOB_ID}_${i}  \n    sleep 1\ndone\n\n# keep the wait statement, it is important!\n\nwait  The script assumes that the job is described in a script file\n\u201cworkScript.sh\u201d, which takes a single number identifying the job\ndirectory to be accessed as a command line argument. Please note the\n\u201csleep 1\u201d command inside the do loop. In our testing this greatly\nenhances the stability by submitting the actual jobs over a longer\nperiod of time. With this statement included the script was able to\nsuccessfully handle up to about 800 outstanding jobs on 16 and 32 cores.\nFor reasons of job reliability, we therefore recommend not to process\nmore than 800 jobs in a single script. However it is possible to process\nsignificantly larger job numbers than 800 by carefully tuning sleep-time\nand core count in relation to the average job-time.  Remarks:  When using srun inside a batch script many srun-options act\ndifferently compared to using srun within a different environment.\nConsult the man-page of srun for documentation and contact the Lunarc\nhelp desk if your require further consultancy.  The worker script  This outlines the worker script. Compared to the script describing a single serial job , a few modifications are\nrequired:    To avoid access conflicts between the individual jobs, each job\n      creates a job private sub-directory on the node local disk.    The input file(s) are expected in the sub_directories job_0,\n      job_1, job_2, \u2026 of the submission directory. The result file(s)\n      will also be placed in these directories.    The example assumes a single input file and single result file. If\n      you have multiple input and/or result files modifications are\n      needed, as are modifications for that actual names of your file    The present set up allows for different executables for each\n      job-stop. The script assumes to find an executable named\n      \u201cprocessor\u201d in the same location as the input file(s). If you all\n      job steps use the same executable the scripts can be simplified.    Once a job-step has finished and the result file has been copied\n      back, the job private sub-directory on the node local disk is\n      removed to prevent the disc from overflow.    If you are using the above master script, the script should be named\n\u201cworkScript.sh\u201d.  #!/bin/sh\n# document this script to stdout (assumes redirection from caller)\ncat $0\n\n# receive my worker number\nexport WRK_NB=$1\n\n# create worker-private subdirectory in $SNIC_TMP\nexport WRK_DIR=$SNIC_TMP/WRK_${WRK_NB}\nmkdir $WRK_DIR\n\n# create a variable to address the  job directory \nexport JOB_DIR=$SLURM_SUBMIT_DIR/job_${WRK_NB}\n\n# now copy the input data and program from there\n\ncd $JOB_DIR\n\ncp -p input.dat processor $WRK_DIR\n\n# change to the execution directory\n\ncd $WRK_DIR\n\n# run the program\n\n./processor\n\n# rescue the results back to job directory\n\ncp -p result.dat ${JOB_DIR}\n\n# clean up the local disk and remove the worker-private directory\n\ncd $SNIC_TMP\n\nrm -rf WRK_${WRK_NB}  Monitoring the progress of your multi-job submission  Using the -s option of sbatch you can monitor the progression of the\nindividual job-steps of your multi-job submission. Please keep in mind,\nthat the step number SLURM assigns to your job and the one you assign\ntypically differs from the loop index used in the master script.  The below is an output from squeue when running a script processing 500\njobs on 32 cores. The jobid of the job is 8070. The output shows the\njob-steps the script is presently processing  [fred@alarik MultiSerialTest]$ squeue -j 8070 -s\nSTEPID NAME PARTITION USER TIME NODELIST\n8070.130 small_ex snic fred 2:09 an074\n8070.133 small_ex snic fred 2:02 an073\n8070.135 small_ex snic fred 1:55 an074\n8070.136 small_ex snic fred 1:41 an073\n8070.139 small_ex snic fred 1:41 an073\n8070.140 small_ex snic fred 1:41 an073\n8070.143 small_ex snic fred 1:41 an073\n8070.144 small_ex snic fred 1:41 an074\n8070.147 small_ex snic fred 1:41 an074\n8070.148 small_ex snic fred 1:41 an074\n8070.151 small_ex snic fred 1:41 an074\n8070.155 small_ex snic fred 1:38 an074\n8070.156 small_ex snic fred 1:35 an074\n8070.157 small_ex snic fred 1:34 an073\n8070.158 small_ex snic fred 1:34 an073\n8070.159 small_ex snic fred 1:34 an073\n8070.161 small_ex snic fred 1:34 an073\n8070.164 small_ex snic fred 1:33 an074\n8070.165 small_ex snic fred 1:33 an074\n8070.168 small_ex snic fred 1:32 an073\n8070.170 small_ex snic fred 1:26 an073\n8070.171 small_ex snic fred 1:12 an073\n8070.172 small_ex snic fred 1:12 an073\n8070.175 small_ex snic fred 1:11 an074\n8070.176 small_ex snic fred 1:11 an074\n8070.179 small_ex snic fred 1:11 an074\n8070.184 small_ex snic fred 1:04 an074\n8070.185 small_ex snic fred 0:42 an073\n8070.190 small_ex snic fred 0:35 an073\n8070.193 small_ex snic fred 0:35 an074\n8070.194 small_ex snic fred 0:13 an073\n8070.195 small_ex snic fred 0:13 an074", 
            "title": "Running multiple serial jobs within a single job submission"
        }, 
        {
            "location": "/batch_system/#mpi-job-using-16-tasks-per-node", 
            "text": "Most MPI jobs achieve best cost efficiency when deploying 16 tasks per\nnode, that is one task per core. Benchmarking by the Lunarc team showed\nthat these jobs typically require binding to achieve good performance.\nThe binding offered by the OpenMPI library works satisfactory.  The resource request is very easy in this case. Ask for a number of\ncores equivalent to the number of tasks you want to run. We recommend\nusing the --exclusive option to avoid getting unrelated jobs placed on\nthe last node in case the number of cores requested doesn\u2019t divide by\nthe number of cores per node. The following is an example submission\nscript to run the MPI application simula_mpi with 64 tasks on 4 nodes.\nNotice you do not need to specify the node count.  #!/bin/sh\n# requesting the number of cores needed on exclusive nodes\n#SBATCH -N 4\n#SBATCH --tasks-per-node=16\n#SBATCH --exclusive\n#\n# job time, change for what your job requires\n#SBATCH -t 0:30:0\n#\n# job name\n#SBATCH -J simula_n64\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o simula_n64_%j.out\n#SBATCH -e simula_n64_%j.out\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# Example assumes we need the intel runtime and OpenMPI library\n# customise for the libraries your executable needs\nmodule add intel/13.0\nmodule add openmpi/1.6.2/intel/13.0\n\n# Copying the executable onto the local disks of the nodes\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp -p simula_mpi $SNIC_TMP\n\n# Copy the input file onto the headnode - if your MPI program\n# reads from all tasks, you need to do the above srun construct\n# again\ncp -p input.dat $SNIC_TMP\n\n# change to local disk and start the mpi executable\ncd $SNIC_TMP\nmpirun -bind-to-core simula_mpi\n\n# Copy result files back - example assumes only task zero writes\n# if in your application result files are written on all nodes\n# you need to initiate a copy on each node via srun\n\ncp -p result.dat $SLURM_SUBMIT_DIR\n```bash\n\nThis script assumes you are using up to 2000 MB of memory per task. If\nyou need more, adding the two lines\n\n    #SBATCH -C mem64GB\n    #SBATCH --mem-per-cpu=4000\n\nto the script will allow for using up to 4000 MB. Since fewer nodes are\nequipped with 64 GB of memory, you have to allow for longer queueing\ntimes until resource become available.\n\n### Modifications required for file I/O on all nodes\n\nAs discussed in the comments of the sample script, the script assumes\nthat only MPI-task 0 on the head node reads the input file and writes to\nthe output file. If for your MPI application every MPI task reads the\ninput file(s), replace the line\n\n    cp -p input.dat $SNIC_TMP\n\nwith\n\n    srun -n $SLURM_NNODES -N $SLURM_NNODES cp -p input.dat $SNIC_TMP\n\nand the file gets copied onto the local disk of each node. Matters are\nslightly more complex, if your output is written from all tasks. We\nassume the output files can be wild-carded as result_*.dat. Copying\nthese files back to the submission directory can be achieved creating a\nscript, which is placed on all nodes and subsequently executed on all\nnodes. The following addition to the submission script will create the\nscript and place it on all your nodes\n\n```bash\ncat  EOF   copyfile.sh\n#!/bin/sh\ncp -p result*.dat $SLURM_SUBMIT_DIR\nEOF\n\nchmod u+x copyfile.sh\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp copyfile.sh $SNIC_TMP  This needs inserting into the script before the \u201ccd $SNIC_TMP\u201d\nstatement. Once this is in place you can copy your result files by\nreplacing the line  cp -p result.dat $SLURM_SUBMIT_DIR  with the line  srun -n $SLURM_NNODES -N $SLURM_NNODES copyfile.sh", 
            "title": "MPI job using 16 tasks per node"
        }, 
        {
            "location": "/batch_system/#mpi-jobs-using-fewer-than-16-tasks-per-node", 
            "text": "If you want to use fewer than 16 task per nodes to e.g. give more\nresources to the individual task, you can use the -N and --task-per-node\noptions of sbatch. We recommend not to use the -n option in this case.\nThis example is for 4 nodes with 8 tasks each, a total of 32 tasks. In\nour experience, in this case and when using --exclusive it is typically\nadvantageous to not use binding. Though we encourage experimenting with\nyour own application.  #!/bin/sh\n# requesting the number of nodes and cores needed, exclusive nodes\n#SBATCH -N 4\n#SBATCH --tasks-per-node=8\n#SBATCH --mem-per-cpu=8000\n#SBATCH -C mem64GB\n#SBATCH --exclusive\n#\n# job time, change for what your job requires\n#SBATCH -t 0:30:0\n#\n# job name\n#SBATCH -J simula_n64\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o simula_n64_%j.out\n#SBATCH -e simula_n64_%j.out\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# Example assumes we need the intel runtime and OpenMPI library\n# customise for the libraries your executable needs\nmodule add intel/13.0\nmodule add openmpi/1.6.2/intel/13.0\n\n# Copying the executable onto the local disks of the nodes\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp -p simula_mpi $SNIC_TMP\n\n# Copy the input file onto the headnode - if your MPI program\n# reads from all tasks, you need to do the above srun construct\n# again\ncp -p input.dat $SNIC_TMP\n\n# change to local disk and start the mpi executable\ncd $SNIC_TMP\nmpirun simula_mpi\n\n# Copy result files back - example assumes only task zero writes\n# if in your application result files are written on all nodes\n# you need to initiate a copy on each node via srun\n\ncp -p result.dat $SLURM_SUBMIT_DIR", 
            "title": "MPI jobs using fewer than 16 tasks per node"
        }, 
        {
            "location": "/batch_system/#openmp-jobs-using-shared-memory", 
            "text": "To run a shared memory code using OpenMP on Alarik, you specify the\nnumber of cores you require using --tasks-per-node option of sbatch. In\nthis case you have to request placement on a single node with the \u201c-N 1\u201d\noption. In this example we call the executable \u201cprocessor_omp\u201d to\nemphasis that this need to be compiled with OpenMP support. Unless you\nare doing something special, you are not required to specify the\nenvironment variable OMP_NUM_THREADS. The example script uses the\ntechniques described for the  basic run script  to\nengage the node local disk.  #!/bin/bash\n#\n# Specify the number of threads - request all on 1 node\n#SBATCH -N 1\n#SBATCH --tasks-per-node=16\n#\n# job time, change for what your job requires\n#SBATCH -t 00:10:00\n#\n# job name\n#SBATCH -J data_process\n#\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o process_omp_%j.out\n#SBATCH -e process_omp_%j.err\n\n# write this script to stdout-file - useful for scripting errors\ncat $0\n\n# copy the input data and program to node local disk\n# customise for your input file(s) and program name\ncp -p input.dat processor_omp $SNIC_TMP\n\n# change to the execution directory\ncd $SNIC_TMP\n\n# run the program\n# customise for your program name and add arguments if required\n./processor_omp\n\n# rescue the results to the submission directory\n# customise for your result file(s)\ncp -p result.dat $SLURM_SUBMIT_DIR  This script allows to use 2000 MB of main memory per requested core. If\nyou need more memory, this can be requested by:  #SBATCH -C mem64GB\n#SBATCH --mem-per-cpu=4000  This will increase you memory request to 4000 MB per requested core.  Thread binding for OpenMP codes  The Alarik nodes deploy a cache-coherent non-uniform-memory access\narchitecture (cc-numa). Many scientific simulation codes gain\nsignificant performance benefits on a cc-numa architecture when the user\nbinds the threads to physical cores of the hardware. This inhibits\nthread migration and improves memory locality. Unfortunately invoking\nthread binding is not standartised. Depending on the OpenMP runtime\nlibrary the user needs to modify different environment variables to bind\nhis threads.  Thread binding with the GNU compilers  By default the GNU compiler suite (gcc/gfortran) does not bind threads\nto cores. To engage thread binding, you need to set the environment\nvariable GOMP_CPU_AFFINITY and provide this with a binding list. When\nsetting  export GOMP_CPU_AFFINITY=\u201d0-15\u201d  in your submission script, prior to starting your OpenMP application,\nthis will bind the threads to the 16 cores in the node. The above will\nbind thread 0 to core 0, thread 1 to core 1 and so on.  More advanced remark:  If you want to utilise only 8 cores from a\nnode and asking for exclusive node access (#SBATCH --exclusive), it\nmight be a good idea to place threads on every second core only. This\nwill give you more memory bandwidth and make sure you are utilising all\nFPUs of the Interlagos architecture. This can be achieved by setting:  export GOMP_CPU_AFFINITY=\u201d0-14:2\u201d  or  export GOMP_CPU_AFFINITY=\u201d0 2 4 6 8 10 12 14\u201d  It depend on details of your application, whether or not this helps\nperformance. Also note, when asking for a exclusive access to a note,\nyou will be charged for the full node, whether or not you use all cores.  Important pitfall:  If you set GOMP_CPU_AFFINITY=0 this will bind\nall threads to core 0. You will see extremely poor performance in this\ncase.  Thread binding with the open64 compiler  OpenMP code compiled with the  open64  compiler will use thread\nbinding on Alarik. In standard use cases this will actually boost\nperformance. However in special situation, e.g. when using fewer threads\nthan the size of your partition, you might see a performance boost by\nnot using thread binding. To do so you need to set the environment\nvariable \u201cO64_OMP_SET_AFFINITY=false\u201d  Thread binding with the Intel compiler  Versions 12.1 and 13.0 of the  Intel  compiler do not support thread\nbinding when used on the AMD processors deployed on Alarik. Starting\nfrom version 13.1 the Intel compile does support thread binding on the\nAMD processors deployed on Alarik. Obviously all versions of the Intel\ncompiler support thread binding on the Intel processors deployed on\nErik.  For version 13.1 of the Intel compiler thread is controlled by setting\nthe environment variable KMP_AFFINITY. The value  export KMP_AFFINITY=granularity=fine,compact  might be a good starting point for your experimentation.", 
            "title": "OpenMP jobs using shared memory"
        }, 
        {
            "location": "/batch_system/#hybrid-jobs-using-threads-within-an-mpi-framework", 
            "text": "A cluster with multicore nodes such as Alarik is a natural environment\nto execute parallel codes deploying both MPI and OpenMP threads. When\nrunning such applications the optimal number of MPI-tasks and OpenMP\nthreads to place on a node can depend highly on the details of the\napplication. In particular for application which make many references to\nmain memory and the programmer has not implemented a proper \u201cfirst touch\ndata allocation\u201d it is typically  best to have 2 or 4 threads  per MPI\ntask on an Alarik node. Together with a proper binding of your MPI tasks\nto the \u201cnuma-islands\u201d, this will ensure memory locality for your code.\nFor the below syntax you have to use  version 1.8.3 or newer  of the\nOpenMPI library.  In the following we give a simple example script to run a MPI-OpenMP\nhybrid named simul_hyb on 2 nodes using 8 tasks and 4 threads per task.\nThe tasks and their threads will be bound to the  numa-islands ,\nminimising cc-numa effects.  #!/bin/sh\n# requesting number of nodes (-N option)\n# number of mpi-tasks per node\n# and number of threads per task exclusive nodes\n#SBATCH -N 2\n#SBATCH --tasks-per-node=4\n#SBATCH --cpus-per-task=4\n#SBATCH --exclusive\n# time required\n#SBATCH -t 01:00:00\n#SBATCH -J hybrid_run\n# filenames stdout and stderr - customise, include %j\n#SBATCH -o simula_N2t4c4_%j.out\n#SBATCH -e simula_N2t4c4_%j.out\n\ncat $0\n\n# Example assumes we need the intel runtime and OpenMPI library\n# customise for the libraries your executable needs\nmodule add intel/15.0\nmodule add openmpi/1.8.3/intel/15.0\n\n# Copying the executable onto the local disks of the nodes\nsrun -n $SLURM_NNODES -N $SLURM_NNODES cp -p simul_hyb $SNIC_TMP\n\n# Copy the input file onto the headnode - if your MPI program\n# reads from all tasks, you need to do the above srun construct\n# again\ncp -p input.dat $SNIC_TMP\ncd $SNIC_TMP\n\n# setting number of OpenMP threads and ask for thread binding\nexport OMP_NUM_THREADS=$SLURM_CPUS_PER_TASK\nexport OMP_PROC_BIND=true\n\nmpiexec --map-by ppr:$SLURM_NTASKS_PER_NODE:node:PE=$SLURM_CPUS_PER_TASK simul_hyb\n\n# Copy result files back - example assumes only task zero writes\n# if in your application result files are written on all nodes\n# you need to initiate a copy on each node via srun\ncp -p result.dat $SLURM_SUBMIT_DIR  The example assumes that MPI task 0 is the only task reading and writing\ninput files. If your application reads and writes data on all nodes, you\nneed to study the  modifications  described in the\nMPI section.  As discussed, the above binds the tasks and their threads to the\nnuma-islands of the Alarik architecture. Alariks numa-islands have four\ncores, therefore the script is best used with 2 or four threads per MPI\ntask. This results in one or two MPI tasks per numa islands.  Things to try for MPI-OpenMP hybrids with 16 threads per task  While using more than 4 threads per MPI task on the Alarik system can\nresult in reduced performance due to cc-numa effects, there are\nsituations when using 16 threads per task can be required (e.g. special\nalgorithms or extreme memory requirements per MPI task).  When running 16 threads per MPI task, that is a single MPI task per\nAlarik node, you might want to experiment with starting your job without\nspecifying binding on mpiexec, that is remove the -bind-to-core, but\nutilise the  OpenMP thread binding  techniques\ndescribed in the OpenMP sample section.", 
            "title": "Hybrid-jobs using threads within an MPI framework"
        }, 
        {
            "location": "/batch_system/#interactive-access-to-compute-nodes", 
            "text": "Sometimes it is desirable to have an interactive login to the compute\nnodes of the cluster. Extensive code testing is a typical use case.", 
            "title": "Interactive access to compute nodes"
        }, 
        {
            "location": "/batch_system/#starting-an-interactive-session", 
            "text": "To start an interactive session you need to use the \u201cinteractive\u201d\ncommand. This will request the required resources from the resource pool\nfor you and start the interactive session once the resources are\navailable.  Use the following command to start an interactive session asking for 32\ncores lasting 60 minutes  interactive -n 32 -t 60  On Alarik and Eric this will be allocated on multiple nodes, since the\nnodes have only 16 cores available. The interactive session will last\nuntil either the requested time, 60 minutes in the above example, has\nexpired or you manually exit the interactive shell. Your account gets\ncharged with the wall time duration of your interactive session,\nindependent of the amount of computation you do. In the above example,\nif your session lasts until it expires after 60 min, you get charged for\n32 cpu hours. If you terminate your session after 1/2 hour, you would\nget charged 16 cpu hours.  The interactive command supports most command line options of the sbatch\ncommand. Please refer to the man pages of sbatch.", 
            "title": "Starting an interactive session"
        }, 
        {
            "location": "/batch_system/#modules-and-environment-variables", 
            "text": "Loaded modules and environment are not always exported properly to your\ninteractive session. Once placed in the interactive session, we\nrecommend users to reload  all  the modules they require. That is\ndespite the \u201cmodules list\u201d command claiming they are still loaded.  You also need to check whether environment variables still have the\nrequired values. If the software you are using has a set-up script, you\nmight need to re-run that script.", 
            "title": "Modules and environment variables"
        }, 
        {
            "location": "/batch_system/#known-issues-with-the-interactive-command", 
            "text": "None at the time of writing.", 
            "title": "Known issues with the interactive command"
        }, 
        {
            "location": "/aurora_modules/", 
            "text": "Using supported software on Lunarc's Aurora service\n\n\nAuthor: Joachim Hein (Lunarc)\n\n\nHierachical module naming scheme\n\n\nWith the start of the Aurora service Lunarc is using an hierachical module naming scheme.  Hierachical modules ensure that the correct shared libraries are available when running an application, while keeping screen output of standard module commands such as \nmodule avail\n managable.\n\n\nHierachical naming scheme concept\n\n\nWhen loging into the system, you only get access to those modules that do not require any special dynamic libraries.  After \nloading a compiler module\n you obtaing access to those packages that have been build with that specific compiler and depend on its shared libraries.  For many compilers this will include one or more matching MPI libraries.  After loading an MPI library additional software packages, depending on this pair (compiler \n MPI library), will become available.  Users should take note that in many cases loading an MPI library is required for software that doesn't really depend on it.\n\n\nUsing Modules\n\n\nThe module system on Aurora is utilising the Lua based \nLmod\n software.\n\n\nLoading packages\n\n\nThe command\n\n\nmodule avail\n\n\n\n\nshows the modules that can currently be accessed.  The output will look similar to\n\n\n--------------------------------- /sw/Modules/modulefiles/Core ---------------------------------\n   matlab/8.5\n\n-------------------------------- /sw/easybuild/modules/all/Core --------------------------------\n   Bison/3.0.4                    gompi/2015b\n   EasyBuild/2.5.0                gompi/2016a                        (D)\n   EasyBuild/2.6.0         (D)    icc/2015.3.187-GNU-4.9.3-2.25\n   GCC/4.9.3-binutils-2.25        icc/2016.1.150-GCC-4.9.3-2.25      (D)\n   GCC/4.9.3-2.25                 iccifort/2015.3.187-GNU-4.9.3-2.25\n   GCC/5.3.0               (D)    iccifort/2016.1.150-GCC-4.9.3-2.25 (D)\n   GCCcore/4.9.3                  ifort/2015.3.187-GNU-4.9.3-2.25\n   GNU/4.9.3-2.25                 ifort/2016.1.150-GCC-4.9.3-2.25    (D)\n   Java/1.8.0_72                  iimpi/7.3.5-GNU-4.9.3-2.25\n   M4/1.4.17                      iimpi/2016.01-GCC-4.9.3-2.25       (D)\n   binutils/2.25                  intel/2015b\n   flex/2.5.39                    intel/2016a\n   foss/2015b                     intel/2016.01                      (D)\n   foss/2016a              (D)    zlib/1.2.8\n\n-------------------------------- /sw/lmod/lmod/modulefiles/Core --------------------------------\n   lmod/6.0.24    settarg/6.0.24\n\n\n\n\nIn this example you can see modules and versions located in 3 directories.  Any of these modules can be accessed directly.  To obtain access to the software inside e.g. the toolchain module \nfoss/2016a\n one loads the module by issueing\n\n\nmodule load foss/2016a\n\n\n\n\nMany modules will load a number of modules, which they depend on.\nSince in the above output from \nmodule avail\n version 2016a is marked\nas the default version, the command\n\n\nmodule load foss\n\n\n\n\nwould have the same effect unless the default changes, which it may\ndo, if\n\n\n\n\nYou load a module\n\n\nThe lunarc team installs another version of the software\n\n\n\n\nSo if you require a specific version, the Lunarc team strongly\nrecommends to not rely on defaults, but explicitly specify the version\nyou are after.\n\n\nTo see what modules you have currently loaded use\n\n\nmodule list\n\n\n\n\nIn a hierachical module naming scheme the command \nmodule avail\n is\nnot as useful as it is in a flat module naming scheme which Lunarc\ndeployed on earlier services.   In many situations \nmodule avail\n\nresulted in the desired action, one has to use the \nmodule spider\n\ncommand which is descripted in the text below.\n\n\nPurging the loaded modules\n\n\nMany modules will load a number extra of modules, which they depend on.\nWhen unloading a  module, these dependencies will typically not be unloaded.  For\nthat reason we currently recommend using\n\n\nmodule purge\n\n\n\n\nwhen loaded modules are no longer needed.   You would then start\nloading the modules required for the next task you need to accomplish\nfrom scratch.\n\n\nSeaching for all software packages\n\n\nIn practical use, the command \nmodule spider\n is key to search for packages in an Lmod based hierachical module naming scheme.  To get an overview on the software installed on Aurora, simply type\n\n\nmodule spider\n\n\n\n\nat the command prompt.  This will create an output similar to:\n\n\n---------------------------------------------------------------------\nThe following is a list of the modules currently available:\n---------------------------------------------------------------------\n  Autoconf: Autoconf/2.69\n\n  Automake: Automake/1.15\n\n  Autotools: Autotools/20150215\n\n  Bison: Bison/3.0.4\n\n  Boost: Boost/1.58.0-Python-2.7.9\n\n  CMake: CMake/3.2.2, CMake/3.3.2\n\n  Cube: Cube/4.3\n\n  EasyBuild: EasyBuild/2.5.0, EasyBuild/2.6.0\n\n  FFTW: FFTW/3.3.4\n\n  GCC: GCC/4.9.3-binutils-2.25, GCC/4.9.3-2.25, GCC/5.3.0\n\n  GCCcore: GCCcore/4.9.3\n\n  GLib: GLib/2.42.1, GLib/2.46.0\n\n  GNU: GNU/4.9.3-2.25\n\n  GROMACS: GROMACS/5.0.4-mt, GROMACS/5.0.5-hybrid\n\n  ...\n\n\n\n\nThis is a full list of the packages and versions available on the service.  \n\n\nSearching for a specific package\n\n\nIf you are looking for a specific package and have an idea on what its name might be, you can give this as an argument to \nmodule spider\n.   This argument is case insensitive.  \n\n\nExample: Accessing a Gromacs version\n\n\nFor example, when looking to run Gromacs:\n\n\nmodule spider gromacs\n\n\n\n\nYou obtain output simlar to:\n\n\n---------------------------------------------------------------------------------\n  GROMACS:\n---------------------------------------------------------------------------------\n     Versions:\n        GROMACS/5.0.4-mt\n        GROMACS/5.0.5-hybrid\n\n---------------------------------------------------------------------------------\n  To find detailed information about GROMACS please enter the full name.\n  For example:\n\n     $ module spider GROMACS/5.0.5-hybrid\n---------------------------------------------------------------------------------\n\n\n\n\nThis tells you that the multi threaded version 5.0.4 and the hybrid version 5.0.5 are installed.  If you want to use the version 5.0.5 issue the command:\n\n\nmodule spider GROMACS/5.0.5-hybrid\n\n\n\n\nYou get the folling output\n\n\n---------------------------------------------------------------------------------\n  GROMACS: GROMACS/5.0.5-hybrid\n---------------------------------------------------------------------------------\n\n    This module can only be loaded through the following modules:\n\n      icc/2016.1.150-GCC-4.9.3-2.25  impi/5.1.2.150\n      ifort/2016.1.150-GCC-4.9.3-2.25  impi/5.1.2.150\n\n... \n\n\n\n\nThis lists the modules you have to load before accessing Gromacs.  In this case you have two options, we choose the first option.  We load\n\n\nmodule load icc/2016.1.150-GCC-4.9.3-2.25\nmodule load impi/5.1.2.150\n\n\n\n\nAfter which we can load the gromacs installation:\n\n\nmodule load GROMACS/5.0.5-hybrid\n\n\n\n\nLoading this module will load a number of additional module require for Gromacs to work.\n\n\nExample accessing R\n\n\nThis is another example on how to access a specific software package.  This time we want to run the statistical software package R.\n\n\nmodule spider R\n\n\n\n\nOne gets:\n\n\n------------------------------------------------------------------\n  R:\n------------------------------------------------------------------\n     Versions:\n        R/3.2.1-bare\n        R/3.2.1\n        R/3.2.3\n\n     Other possible modules matches:\n        GCCcore  GROMACS  SuiteSparse  cURL  fixesproto  fontsproto  ...\n\n------------------------------------------------------------------\n  To find other possible module matches do:\n      module -r spider '.*R.*'\n\n------------------------------------------------------------------\n  To find detailed information about R please enter the full name.\n  For example:\n\n     $ module spider R/3.2.1-bare\n------------------------------------------------------------------\n\n\n\n\nIf we are interested in version 3.2.3, we do a\n\n\nmodule spider R/3.2.3\n\n\n\n\nnext and get the following info:\n\n\n------------------------------------------------------------------\n  R: R/3.2.3\n------------------------------------------------------------------\n\n     Other possible modules matches:\n        GCCcore, GROMACS, SuiteSparse, cURL, fixesproto, ...\n\n    This module can only be loaded through the following modules:\n\n      GCC/4.9.3-binutils-2.25  OpenMPI/1.8.8\n\n...\n\n\n\n\nThe output states the two modules that need loading to get access to this R version.  We issue\n\n\nmodule load GCC/4.9.3-binutils-2.25\nmodule load OpenMPI/1.8.8\nmodule load R/3.2.3\n\n\n\n\nand have acces to R.\n\n\nLmod cache\n\n\nTo improve the performance of the \nmodule spider\n command, lmod caches\nthe entire module structure of the system.  This cache is currently\nconfigured to be updated once in 24 hours.\n\n\nThis can have the effect that you see an outdated version of the\nmodule tree, when using commands such as \nmodule avail\nor \nmodule\nspider\n.   The cache file is stored in the directory\n\n$HOME/.lmod.d/.cache/\n remove the cache file and lmod will recreate\nit for you.\n\n\nToolchains\n\n\nA signficant portion of the Aurora software is build \nEasyBuild\n software framework.  This frame work provides so called \nToolchains\n which are utilised to build software.  Lunarc recommends using these toolchains even when building software outside the EasyBuild framework.\n\n\nLunarc actively maintains the following toolchains\n+ \nfoss\n: BLACS, FFTW, GCC, OpenBLAS, OpenMPI, ScaLAPACK\n+ \ngompi\n: GCC, OpenMPI\n+ \nintel\n: icc, ifort, MKL, Intel MPI\n+ \niimpi\n: icc, ifort, Intel MPI\n\n\nIf you require additional toolchains, contact \nLunarc support\n to discuss your requirements.", 
            "title": "Aurora Software"
        }, 
        {
            "location": "/aurora_modules/#using-supported-software-on-lunarcs-aurora-service", 
            "text": "Author: Joachim Hein (Lunarc)", 
            "title": "Using supported software on Lunarc's Aurora service"
        }, 
        {
            "location": "/aurora_modules/#hierachical-module-naming-scheme", 
            "text": "With the start of the Aurora service Lunarc is using an hierachical module naming scheme.  Hierachical modules ensure that the correct shared libraries are available when running an application, while keeping screen output of standard module commands such as  module avail  managable.", 
            "title": "Hierachical module naming scheme"
        }, 
        {
            "location": "/aurora_modules/#hierachical-naming-scheme-concept", 
            "text": "When loging into the system, you only get access to those modules that do not require any special dynamic libraries.  After  loading a compiler module  you obtaing access to those packages that have been build with that specific compiler and depend on its shared libraries.  For many compilers this will include one or more matching MPI libraries.  After loading an MPI library additional software packages, depending on this pair (compiler   MPI library), will become available.  Users should take note that in many cases loading an MPI library is required for software that doesn't really depend on it.", 
            "title": "Hierachical naming scheme concept"
        }, 
        {
            "location": "/aurora_modules/#using-modules", 
            "text": "The module system on Aurora is utilising the Lua based  Lmod  software.", 
            "title": "Using Modules"
        }, 
        {
            "location": "/aurora_modules/#loading-packages", 
            "text": "The command  module avail  shows the modules that can currently be accessed.  The output will look similar to  --------------------------------- /sw/Modules/modulefiles/Core ---------------------------------\n   matlab/8.5\n\n-------------------------------- /sw/easybuild/modules/all/Core --------------------------------\n   Bison/3.0.4                    gompi/2015b\n   EasyBuild/2.5.0                gompi/2016a                        (D)\n   EasyBuild/2.6.0         (D)    icc/2015.3.187-GNU-4.9.3-2.25\n   GCC/4.9.3-binutils-2.25        icc/2016.1.150-GCC-4.9.3-2.25      (D)\n   GCC/4.9.3-2.25                 iccifort/2015.3.187-GNU-4.9.3-2.25\n   GCC/5.3.0               (D)    iccifort/2016.1.150-GCC-4.9.3-2.25 (D)\n   GCCcore/4.9.3                  ifort/2015.3.187-GNU-4.9.3-2.25\n   GNU/4.9.3-2.25                 ifort/2016.1.150-GCC-4.9.3-2.25    (D)\n   Java/1.8.0_72                  iimpi/7.3.5-GNU-4.9.3-2.25\n   M4/1.4.17                      iimpi/2016.01-GCC-4.9.3-2.25       (D)\n   binutils/2.25                  intel/2015b\n   flex/2.5.39                    intel/2016a\n   foss/2015b                     intel/2016.01                      (D)\n   foss/2016a              (D)    zlib/1.2.8\n\n-------------------------------- /sw/lmod/lmod/modulefiles/Core --------------------------------\n   lmod/6.0.24    settarg/6.0.24  In this example you can see modules and versions located in 3 directories.  Any of these modules can be accessed directly.  To obtain access to the software inside e.g. the toolchain module  foss/2016a  one loads the module by issueing  module load foss/2016a  Many modules will load a number of modules, which they depend on.\nSince in the above output from  module avail  version 2016a is marked\nas the default version, the command  module load foss  would have the same effect unless the default changes, which it may\ndo, if   You load a module  The lunarc team installs another version of the software   So if you require a specific version, the Lunarc team strongly\nrecommends to not rely on defaults, but explicitly specify the version\nyou are after.  To see what modules you have currently loaded use  module list  In a hierachical module naming scheme the command  module avail  is\nnot as useful as it is in a flat module naming scheme which Lunarc\ndeployed on earlier services.   In many situations  module avail \nresulted in the desired action, one has to use the  module spider \ncommand which is descripted in the text below.", 
            "title": "Loading packages"
        }, 
        {
            "location": "/aurora_modules/#purging-the-loaded-modules", 
            "text": "Many modules will load a number extra of modules, which they depend on.\nWhen unloading a  module, these dependencies will typically not be unloaded.  For\nthat reason we currently recommend using  module purge  when loaded modules are no longer needed.   You would then start\nloading the modules required for the next task you need to accomplish\nfrom scratch.", 
            "title": "Purging the loaded modules"
        }, 
        {
            "location": "/aurora_modules/#seaching-for-all-software-packages", 
            "text": "In practical use, the command  module spider  is key to search for packages in an Lmod based hierachical module naming scheme.  To get an overview on the software installed on Aurora, simply type  module spider  at the command prompt.  This will create an output similar to:  ---------------------------------------------------------------------\nThe following is a list of the modules currently available:\n---------------------------------------------------------------------\n  Autoconf: Autoconf/2.69\n\n  Automake: Automake/1.15\n\n  Autotools: Autotools/20150215\n\n  Bison: Bison/3.0.4\n\n  Boost: Boost/1.58.0-Python-2.7.9\n\n  CMake: CMake/3.2.2, CMake/3.3.2\n\n  Cube: Cube/4.3\n\n  EasyBuild: EasyBuild/2.5.0, EasyBuild/2.6.0\n\n  FFTW: FFTW/3.3.4\n\n  GCC: GCC/4.9.3-binutils-2.25, GCC/4.9.3-2.25, GCC/5.3.0\n\n  GCCcore: GCCcore/4.9.3\n\n  GLib: GLib/2.42.1, GLib/2.46.0\n\n  GNU: GNU/4.9.3-2.25\n\n  GROMACS: GROMACS/5.0.4-mt, GROMACS/5.0.5-hybrid\n\n  ...  This is a full list of the packages and versions available on the service.", 
            "title": "Seaching for all software packages"
        }, 
        {
            "location": "/aurora_modules/#searching-for-a-specific-package", 
            "text": "If you are looking for a specific package and have an idea on what its name might be, you can give this as an argument to  module spider .   This argument is case insensitive.    Example: Accessing a Gromacs version  For example, when looking to run Gromacs:  module spider gromacs  You obtain output simlar to:  ---------------------------------------------------------------------------------\n  GROMACS:\n---------------------------------------------------------------------------------\n     Versions:\n        GROMACS/5.0.4-mt\n        GROMACS/5.0.5-hybrid\n\n---------------------------------------------------------------------------------\n  To find detailed information about GROMACS please enter the full name.\n  For example:\n\n     $ module spider GROMACS/5.0.5-hybrid\n---------------------------------------------------------------------------------  This tells you that the multi threaded version 5.0.4 and the hybrid version 5.0.5 are installed.  If you want to use the version 5.0.5 issue the command:  module spider GROMACS/5.0.5-hybrid  You get the folling output  ---------------------------------------------------------------------------------\n  GROMACS: GROMACS/5.0.5-hybrid\n---------------------------------------------------------------------------------\n\n    This module can only be loaded through the following modules:\n\n      icc/2016.1.150-GCC-4.9.3-2.25  impi/5.1.2.150\n      ifort/2016.1.150-GCC-4.9.3-2.25  impi/5.1.2.150\n\n...   This lists the modules you have to load before accessing Gromacs.  In this case you have two options, we choose the first option.  We load  module load icc/2016.1.150-GCC-4.9.3-2.25\nmodule load impi/5.1.2.150  After which we can load the gromacs installation:  module load GROMACS/5.0.5-hybrid  Loading this module will load a number of additional module require for Gromacs to work.  Example accessing R  This is another example on how to access a specific software package.  This time we want to run the statistical software package R.  module spider R  One gets:  ------------------------------------------------------------------\n  R:\n------------------------------------------------------------------\n     Versions:\n        R/3.2.1-bare\n        R/3.2.1\n        R/3.2.3\n\n     Other possible modules matches:\n        GCCcore  GROMACS  SuiteSparse  cURL  fixesproto  fontsproto  ...\n\n------------------------------------------------------------------\n  To find other possible module matches do:\n      module -r spider '.*R.*'\n\n------------------------------------------------------------------\n  To find detailed information about R please enter the full name.\n  For example:\n\n     $ module spider R/3.2.1-bare\n------------------------------------------------------------------  If we are interested in version 3.2.3, we do a  module spider R/3.2.3  next and get the following info:  ------------------------------------------------------------------\n  R: R/3.2.3\n------------------------------------------------------------------\n\n     Other possible modules matches:\n        GCCcore, GROMACS, SuiteSparse, cURL, fixesproto, ...\n\n    This module can only be loaded through the following modules:\n\n      GCC/4.9.3-binutils-2.25  OpenMPI/1.8.8\n\n...  The output states the two modules that need loading to get access to this R version.  We issue  module load GCC/4.9.3-binutils-2.25\nmodule load OpenMPI/1.8.8\nmodule load R/3.2.3  and have acces to R.", 
            "title": "Searching for a specific package"
        }, 
        {
            "location": "/aurora_modules/#lmod-cache", 
            "text": "To improve the performance of the  module spider  command, lmod caches\nthe entire module structure of the system.  This cache is currently\nconfigured to be updated once in 24 hours.  This can have the effect that you see an outdated version of the\nmodule tree, when using commands such as  module avail or  module\nspider .   The cache file is stored in the directory $HOME/.lmod.d/.cache/  remove the cache file and lmod will recreate\nit for you.", 
            "title": "Lmod cache"
        }, 
        {
            "location": "/aurora_modules/#toolchains", 
            "text": "A signficant portion of the Aurora software is build  EasyBuild  software framework.  This frame work provides so called  Toolchains  which are utilised to build software.  Lunarc recommends using these toolchains even when building software outside the EasyBuild framework.  Lunarc actively maintains the following toolchains\n+  foss : BLACS, FFTW, GCC, OpenBLAS, OpenMPI, ScaLAPACK\n+  gompi : GCC, OpenMPI\n+  intel : icc, ifort, MKL, Intel MPI\n+  iimpi : icc, ifort, Intel MPI  If you require additional toolchains, contact  Lunarc support  to discuss your requirements.", 
            "title": "Toolchains"
        }, 
        {
            "location": "/linux_basics/", 
            "text": "Linux Basics\n\n\nAn introduction to Linux shells and commands\n\n\nShells\n\n\nBefore discussing Linux commands, it is important to understand the general Linux environment. A Lunarc user who has just logged into one of the Lunarc systems gets a terminal window with a prompt. At the prompt, a text-based command can be given. The user has actually entered a shell that interprets the commands given. Each command starts a subshell where the command is executed. If the command is a script that contains other commands, they will be executed in a subshell to the subshell. After execution, the prompt returns and represents the level of the original shell.\n\n\nNormally, the user does not have to consider the levels of shells, but it is good to be aware of them, because some funny effects do not make sense otherwise. For example, a new interactive (sub)shell can be started by the command sh. If this is followed by the command exit, the user just exits the new shell, instead of being logged out of the system, which would be the normal result. The shell levels are also important for shell variables (see next section).\n\n\nThere are different kinds of shells with some differences in commands and features. The default shell obtained by a Lunarc user is known as Bourne-Again shell (bash), combining features of Bourne shell (sh, a very early shell and the origin of the pun intended by the bash name), Korn shell (ksh), and C shell (csh). In the following, bash will be assumed, since users who have asked for ksh or csh are supposed to be familiar with their shell of choice.\n\n\nFiles\n\n\nOrganisation\n\n\nFiles and directories are organised in a tree structure, with the top directory, known as the root directory, simply represented by /, which is also the separator for different directory levels. For example, the home directory of user xxxx is /home/xxxx, where home is a directory under / and xxxx a directory under home. A file in the home directory would be represented as /home/xxxx/xfile. This representation is known as a path and if it starts from the root directory, it is a full path.\n\n\nIf the user is in the home directory, the file can simply be specified as xfile, i.e., using a path relative to the current directory. A re relative path can be made more explicit by using the special symbols . (a period), which represents the current directory, and .. (two periods), which denotes the directory one level up. For example, when the user is in the home directory, xfile and ./xfile are equivalent. If the user is in a subdirectory /home/xxxx/subdir1, the file would be represented by ../xfile. Relative levels can be added; i.e., ../../ means two levels up and from /home/xxxx/subdir1/subsubdir1, /home/xxxx/subdir2/subsubdir2/subfile can be specified as ../../subdir2/subsubdir2/subfile.\n\n\nAnother path symbol is ~, which succeeded by a / denotes the home directory of the user. Thus, ~/xfile points to the file in the example in the same way as if the full path /home/xxxx/xfile had been given.\n\n\nShortcuts\n\n\nInstead of typeing a long file name, it is possible to write the first few characters and then press the tab key. If the rest of the file name is unique, it will be completed. If more than one file have the same beginning, the name will be completed up to the first point of difference. A second pressing of the tab key will give the possible alternatives. This works for files and directories in the current directory as well as for commands.\n\n\nTypeing can also be reduced by the use of the wildcard \n. It matches anything in the current directory, which means that the wildcard on its own gives a list of all files and directories in the current directory. If it is combined with characters, names that contain those characters in the corresponding place will be matched. For example, \nfile will match file, xfile, and morefile, but not xfile2. The latter will be matched by \nfile\n, \nfi\n2, and x*2.\n\n\nPermissions\n\n\nUsing the command ls -l to list files in adirectory can give something like\n\n\n-rw-r--r-- 1 xxxx xgroup 38 Feb 22 17:08 file1 \n-rw-rw-r-- 1 xxxx xgroup 50 Feb 22 17:08 file2 \nlrwxrwxrwx 1 xxxx xgroup 5 Feb 22 17:14 link1 -\n file2 \n-rwxr-xr-x 1 xxxx xgroup 91 Feb 22 17:08 script1 \ndrwx------ 2 xxxx xgroup 4096 Feb 22 17:07 subdir1\n\n\n\nThe very first character of each line indicate if the file is of a special kind, such as a link (l) or a directory (d). The next nine characters are the permissions in groups of three for the user (xxxx), group (xgroup), and others. The three types of permissions are read (r), write (w), and execute (x). Thus, in the example, anyone can read file1, but only the user can modify the file, provided the permissions of the directory allow anyone to go there. file2 can also be modfied by members of group xgroup\n\n\nTo run a shell script or a program, it must be executable, at least for the user. script1 can be run by anyone. Similarly, to enter a directory it has to be executable. Only the user xxxx may enter the directory subdir1 in the example.\n\n\nShell Parameters\n\n\nIt is possible to assign values to parameters within a shell. Certain parameters, environment  or shell variables, have to be defined for the proper function of the shell and are usually set automatically. Some shell variables are modified when modules are loaded (see the User's Guide). The user can also define his/her own parameters.\n\n\nShell variables set by the system have names in capital letters. Note that Linux shells are case sensitive; i.e., parameters or commands with names like PARAMETER, PARAmeter, and parameter are all different. The value of a parameter is represented by the name of the parameter preceded by a dollar sign ($) and the value can be checked with the command echo. For example,\n\n\necho $PWD\n\n\n\ngives the path of the current directory and\n\n\necho $HOME\n\n\n\nproduces the path of the home directory. Consequently, the file xfile in the examples above can also be addressed as $HOME/xfile. The interpretation of a parameter name ends at a special character, which is why the last substitution works, but if the parameter is to be used for substitution in a string of characters, the name can be protected by brackets,\n\n\nProgram=myprog\nJobNr=1\nOutputFile=${Program}_job$JobNr.out\n\n\n\nNote that an underscore (_) counts as ordinary text and is not a special character, while a period (.) is the latter.\n\n\nA very important shell variable is PATH. It contains a list of paths where the shell will look for commands, which are actually files containing programs. A selected part of the default PATH on Milleotto is\n\n\n/usr/kerberos/bin:/usr/lpp/mmfs/bin/:/usr/local/bin:/bin:/usr/bin\n\n\n\nThere are two things to note here. First, the order is important. If a command or program with the same name exists in more than one of the directories, the shell will pick the one that comes first in the list. Second, a standard name for a directory is bin. A user can customise the environment by defining and modifying shell variables in the file .bash_profile, which resides in the home directory. On MIlleotto, the default file contains the lines\n\n\nPATH=$PATH:$HOME/bin \nexport PATH\n\n\n\nThis adds a bin directory in the home directory of the user to the search path. The second line is needed to make the change propagate to all subshells. Without the export command the modification of PATH would only have an effect in the shell where the file is executed as a script. This is general. If a parameter is supposed to be defined anywhere else besides the shell where it is initated, it has to be exported. It can be defined and exported in one go, for example,\n\n\nexport WorkDir=/disk/global/xxxx/workdir\n\n\n\nTo list all the defined and exported parameters the command set can be used.\n\n\nThe result of a command can also be put into a parameter by using the grave accent for \"reverse quotation\", for example,\n\n\nThisMachine=`hostname`\n\n\n\nor by the substitution $(command)\n\n\nThisMachine=$(hostname)\n\n\n\nTo put the results of integer arithmetics into a parameter, the command  expr can be used\n\n\nNumber=4 Sum=`expr $Number + 1`\n\n\n\nNote that it is necessary to separate the elements of the expression by spaces. An alternative is the arithmetic substitution $((expression))\n\n\nSum=$(($Number+1))\n\n\n\nNo spaces necessary. In both cases, echo $Sum gives 5.\n\n\nSpecial Command Symbols\n\n\nRedirection\n\n\n file Reads input from the file file.\n\n\n\n\nfile Writes standard output to the file file; i.e., an old file with the same name will be overwritten.\n\n\n\n\nfile Appends standard output to the file file; i.e., the information will be added at the end of the file file, if it already exists.\n\n\n\n\n\n\n2\n file Writes standard error to the file file.\n\n\n file Writes standard output and error to the file file.\n\n\nmyprog \noutfile 2\nerrfile\n\n\nCommand execution\n\n\n; Separates multiple commands on the command line; i.e., the semi-colon corresponds to pressing ENTER between commands.\n\n\ncommand1 ; command2\n\n\n\nis the same as\n\n\ncommand1 command2\n\n\n\n| Pipe symbol. Uses output from one command as input for the next command; i.e.,\n\n\ncommand1 | command2\n\n\n\nis the same as\n\n\ncommand1 \n outfile command2 \n outfile\n\n\n\n!string repeats a previous command line that starts with the string string.\n\n\necho $PATH ... !echo\n\n\n\nThe last line corresponds to executing echo $PATH again.\n\n\nQuotation\n\n\n' ' (Single quotes) Quotes the enclosed string exactly.\n\n\nProgram=myprog\nJobNr=1\nOutputFile='${Program}_job$JobNr.out'\necho $OutputFile\n\n\n\ngives ${Program}_job$JobNr.out as output.\n\n\n\" \" (Double quotes) Quotes the enclosed string after variable substitution.\n\n\nProgram=myprog\nJobNr=1\nOutputFile=\"${Program}_job$JobNr.out\"\necho $OutputFile\n\n\n\ngives myprog_job1.out as output\n\n\nUseful Linux Commands\n\n\nAbout Commands\n\n\nman\n\n\nTo get more information about a command type\n\n\nman command\n\n\n\nwhich\n\n\nCheck where the command that will be used resides\n\n\nwhich command\n\n\n\nThis gives the path of the first occurence of command in the directories listed in the envrionment variable PATH. Note that a few commands are picked up directly by the shell, for example, the time command, and the program in the search path will not be executed. If a command behaves differently than expected from the man page, a solution may be to give the full path of the command found by which.\n\n\nManage Shell Variables and Parameters\n\n\necho\n\n\nGive the value of a parameter\n\n\necho $PATH\n\n\n\nset\n\n\nList the values of all defined environment variables alphabetically\n\n\nset\n\n\n\nexport\n\n\nExport a parameter to all future subshells\n\n\nexport parameter\n\n\n\nThe value can be set and exported at the same time, for example,\n\n\nexport MyParameter=myvalue\n\n\n\nManage Files and Directories\n\n\nmkdir\n\n\nMake a directory\n\n\nmkdir dirname\n\n\n\n-p: Make a directory and also any parent directories, if they do not exist\n\n\nmkdir -p parentdir1/parentdir2/dirname\n\n\n\nrmdir\n\n\nRemove an empty directory\n\n\nrmdir dirname\n\n\n\ncd\n\n\nChange the current directory\n\n\ncd dirname\n\n\n\nSome special behaviour:\n\n\ncd\n\n\n\nWithout a name the new directory is the home directory.\n\n\ncd -\n\n\n\nreturns the user to the previous directory.\n\n\ncd ..\n\n\n\nmoves up one level in the file tree.\n\n\nrm\n\n\nRemove a file\n\n\nrm filename\n\n\n\n-r: Remove a file or a directory with all files and directories in it\n\n\nrm -r dirname\n\n\n\n-i: Get a question before taking action (removing files, removing directories, descending in directories)\n\n\nrm -ir dirname\n\n\n\nmv\n\n\nChange the name of a file or directory\n\n\nmv oldname newname\n\n\n\ncp\n\n\nCopy a file to a new file\n\n\ncp oldname newname\n\n\n\nor to another directory\n\n\ncp file1 file2 file3 newlocation\n\n\n\nCopy all files in the current directory to another directory\n\n\ncp * newlocation\n\n\n\n-p: Copy with preserved file settings (modification date, permissions, ownership):\n\n\ncp -p oldname newname\n\n\n\n-r: Copy a directory and its subdirectories\n\n\ncp -r oldname newname\n\n\n\n-u: Copy only files that do not exist or have an earlier modification date in another directory\n\n\ncp -u * newlocation\n\n\n\nls\n\n\nList files in the current directory\n\n\nls\n\n\n\nList the files in another directory\n\n\nls dirname\n\n\n\n-l: List in long format\n\n\n-s: List with size (in blocks by default)\n\n\n-S: List sorted by size\n\n\n-t: List sorted by time\n\n\n-r: Reverse the order of a sorted listing\n\n\n-h: Print size in human-readable form (with units adjusted to size)\n\n\nList files in long format with most recent file last\n\n\nls -ltr\n\n\n\nfind\n\n\nFind a file/directory with a given name and print its path, starting from a given directory\n\n\nfind dirname -name filename\n\n\n\nFind all files that contain a specified string in their name, starting from the current directory\n\n\nfind . -name \"*string*\"\n\n\n\nFind files newer than a specified file, starting from the current directory\n\n\nfind . -newer filename\n\n\n\n-exec ... {} \\;: Execute a command with the found file represented by {}\n\n\nRemove files and directories with a specified string in their name\n\n\nfind . -name \"*string*\" -exec rm -r {} \\;\n\n\n\n-not: Negate an expression\n\n\n-type d: Specify the file type as a directory\n\n\nGet a long-format listing of files with a specified string in their name, as long as they are not directories\n\n\nfind . -name \"*string*\" -not -type d -exec ls -l {} \\;\n\n\n\nfind is a powerful command with many options as a look at the man page will reveal,\n\n\nman find\n\n\n\ndu\n\n\nPrint the disk usage of the current and all subdirectories\n\n\ndu\n\n\n\nPrint the disk usage of a specifed directory and all its subdirectories\n\n\ndu dirname\n\n\n\n-a: Print the size of individual files in addition to diectories\n\n\nPrint the size of a file\n\n\ndu -a filename\n\n\n\n-s: Just print the sum of the disk usage\n\n\n--max-depth=level: Print usage for directories level levels down, where level is a number\n\n\n-k: Print usage in kB\n\n\n-m: Print usage in MB\n\n\n-h: Print usage in human-readable form (with units adjusted after the size)\n\n\nPrint the summed disk usage of the current directory in human-readable form\n\n\ndu -sh\n\n\n\nPrint the disk usage for the current directory and its immediate subdirectories in human-readable form\n\n\ndu -h --max-depth=1\n\n\n\nchmod\n\n\nSet the file permission.\n\n\nMake a file executable for anyone\n\n\nchmod +x filename\n\n\n\nTo be more precise it is possible to specify the changeas a string in the format who-add/remove-permission, where who is one of more of the characters u (user), g (group), and o (others); + means add and - means remove; and permission is one or more of the characters r (read), w (write), and x (execute). For example, to remove read and write permissions for the group and others\n\n\nchmod go-rw filename\n\n\n\n-R: Make the change recursively, i.e., for all files in all subdirectories\n\n\nchmod -R g+w dirname\n\n\n\nText Handling\n\n\ncat\n\n\nList the contents of a file\n\n\ncat filename\n\n\n\nList the contents of several files and put the result in a new file\n\n\ncat file1 file2 file3 \n newfile\n\n\n\nAppend a file to another file\n\n\ncat file1 \n file2\n\n\n\nmore\n\n\nList the contents of a file without scrolling through everything at once\n\n\nmore filename\n\n\n\nDisplay the output of a command without scrolling through everything at once\n\n\ncommand | more\n\n\n\nPressing return gives a new line. Pressing the space bar gives a new page. b gives the previous page if possible (not for the output stream of a command). /string searches for a string. q exists more.\n\n\nless\n\n\nless is similar to more. One of the more important differences is that it also works backwards. For example, pressing b gives the previous page (works also for more on files - first more example, but not pipes - second more example) and ?string searches backwards for a string.\n\n\ngrep\n\n\nPrint lines that contain a specified string in a file\n\n\ngrep string filename\n\n\n\nSearch for and print lines containing a specified string in several files\n\n\ngrep string file1 file2 file3\n\n\n\nSearch for and print lines containing a specified string in all files in the current directory\n\n\ngrep string *\n\n\n\nPrint the lines in the output of a command containing a specified string\n\n\ncommand | grep string\n\n\n\n-i: Ignore the case of the search string (print both upper and lower case matches)\n\n\n-v: Print lines that do not contain the string\n\n\ncommand | grep -v string\n\n\n\ndiff\n\n\nCompare the contents of two files and print differences\n\n\ndiff file1 file2\n\n\n\n--side-by-side: Display the file contents side-by-side with differences marked\n\n\ndiff --side-by-side file1 file2", 
            "title": "Linux Basics"
        }, 
        {
            "location": "/linux_basics/#linux-basics", 
            "text": "An introduction to Linux shells and commands", 
            "title": "Linux Basics"
        }, 
        {
            "location": "/linux_basics/#shells", 
            "text": "Before discussing Linux commands, it is important to understand the general Linux environment. A Lunarc user who has just logged into one of the Lunarc systems gets a terminal window with a prompt. At the prompt, a text-based command can be given. The user has actually entered a shell that interprets the commands given. Each command starts a subshell where the command is executed. If the command is a script that contains other commands, they will be executed in a subshell to the subshell. After execution, the prompt returns and represents the level of the original shell.  Normally, the user does not have to consider the levels of shells, but it is good to be aware of them, because some funny effects do not make sense otherwise. For example, a new interactive (sub)shell can be started by the command sh. If this is followed by the command exit, the user just exits the new shell, instead of being logged out of the system, which would be the normal result. The shell levels are also important for shell variables (see next section).  There are different kinds of shells with some differences in commands and features. The default shell obtained by a Lunarc user is known as Bourne-Again shell (bash), combining features of Bourne shell (sh, a very early shell and the origin of the pun intended by the bash name), Korn shell (ksh), and C shell (csh). In the following, bash will be assumed, since users who have asked for ksh or csh are supposed to be familiar with their shell of choice.", 
            "title": "Shells"
        }, 
        {
            "location": "/linux_basics/#files", 
            "text": "", 
            "title": "Files"
        }, 
        {
            "location": "/linux_basics/#organisation", 
            "text": "Files and directories are organised in a tree structure, with the top directory, known as the root directory, simply represented by /, which is also the separator for different directory levels. For example, the home directory of user xxxx is /home/xxxx, where home is a directory under / and xxxx a directory under home. A file in the home directory would be represented as /home/xxxx/xfile. This representation is known as a path and if it starts from the root directory, it is a full path.  If the user is in the home directory, the file can simply be specified as xfile, i.e., using a path relative to the current directory. A re relative path can be made more explicit by using the special symbols . (a period), which represents the current directory, and .. (two periods), which denotes the directory one level up. For example, when the user is in the home directory, xfile and ./xfile are equivalent. If the user is in a subdirectory /home/xxxx/subdir1, the file would be represented by ../xfile. Relative levels can be added; i.e., ../../ means two levels up and from /home/xxxx/subdir1/subsubdir1, /home/xxxx/subdir2/subsubdir2/subfile can be specified as ../../subdir2/subsubdir2/subfile.  Another path symbol is ~, which succeeded by a / denotes the home directory of the user. Thus, ~/xfile points to the file in the example in the same way as if the full path /home/xxxx/xfile had been given.", 
            "title": "Organisation"
        }, 
        {
            "location": "/linux_basics/#shortcuts", 
            "text": "Instead of typeing a long file name, it is possible to write the first few characters and then press the tab key. If the rest of the file name is unique, it will be completed. If more than one file have the same beginning, the name will be completed up to the first point of difference. A second pressing of the tab key will give the possible alternatives. This works for files and directories in the current directory as well as for commands.  Typeing can also be reduced by the use of the wildcard  . It matches anything in the current directory, which means that the wildcard on its own gives a list of all files and directories in the current directory. If it is combined with characters, names that contain those characters in the corresponding place will be matched. For example,  file will match file, xfile, and morefile, but not xfile2. The latter will be matched by  file ,  fi 2, and x*2.", 
            "title": "Shortcuts"
        }, 
        {
            "location": "/linux_basics/#permissions", 
            "text": "Using the command ls -l to list files in adirectory can give something like  -rw-r--r-- 1 xxxx xgroup 38 Feb 22 17:08 file1 \n-rw-rw-r-- 1 xxxx xgroup 50 Feb 22 17:08 file2 \nlrwxrwxrwx 1 xxxx xgroup 5 Feb 22 17:14 link1 -  file2 \n-rwxr-xr-x 1 xxxx xgroup 91 Feb 22 17:08 script1 \ndrwx------ 2 xxxx xgroup 4096 Feb 22 17:07 subdir1  The very first character of each line indicate if the file is of a special kind, such as a link (l) or a directory (d). The next nine characters are the permissions in groups of three for the user (xxxx), group (xgroup), and others. The three types of permissions are read (r), write (w), and execute (x). Thus, in the example, anyone can read file1, but only the user can modify the file, provided the permissions of the directory allow anyone to go there. file2 can also be modfied by members of group xgroup  To run a shell script or a program, it must be executable, at least for the user. script1 can be run by anyone. Similarly, to enter a directory it has to be executable. Only the user xxxx may enter the directory subdir1 in the example.", 
            "title": "Permissions"
        }, 
        {
            "location": "/linux_basics/#shell-parameters", 
            "text": "It is possible to assign values to parameters within a shell. Certain parameters, environment  or shell variables, have to be defined for the proper function of the shell and are usually set automatically. Some shell variables are modified when modules are loaded (see the User's Guide). The user can also define his/her own parameters.  Shell variables set by the system have names in capital letters. Note that Linux shells are case sensitive; i.e., parameters or commands with names like PARAMETER, PARAmeter, and parameter are all different. The value of a parameter is represented by the name of the parameter preceded by a dollar sign ($) and the value can be checked with the command echo. For example,  echo $PWD  gives the path of the current directory and  echo $HOME  produces the path of the home directory. Consequently, the file xfile in the examples above can also be addressed as $HOME/xfile. The interpretation of a parameter name ends at a special character, which is why the last substitution works, but if the parameter is to be used for substitution in a string of characters, the name can be protected by brackets,  Program=myprog\nJobNr=1\nOutputFile=${Program}_job$JobNr.out  Note that an underscore (_) counts as ordinary text and is not a special character, while a period (.) is the latter.  A very important shell variable is PATH. It contains a list of paths where the shell will look for commands, which are actually files containing programs. A selected part of the default PATH on Milleotto is  /usr/kerberos/bin:/usr/lpp/mmfs/bin/:/usr/local/bin:/bin:/usr/bin  There are two things to note here. First, the order is important. If a command or program with the same name exists in more than one of the directories, the shell will pick the one that comes first in the list. Second, a standard name for a directory is bin. A user can customise the environment by defining and modifying shell variables in the file .bash_profile, which resides in the home directory. On MIlleotto, the default file contains the lines  PATH=$PATH:$HOME/bin \nexport PATH  This adds a bin directory in the home directory of the user to the search path. The second line is needed to make the change propagate to all subshells. Without the export command the modification of PATH would only have an effect in the shell where the file is executed as a script. This is general. If a parameter is supposed to be defined anywhere else besides the shell where it is initated, it has to be exported. It can be defined and exported in one go, for example,  export WorkDir=/disk/global/xxxx/workdir  To list all the defined and exported parameters the command set can be used.  The result of a command can also be put into a parameter by using the grave accent for \"reverse quotation\", for example,  ThisMachine=`hostname`  or by the substitution $(command)  ThisMachine=$(hostname)  To put the results of integer arithmetics into a parameter, the command  expr can be used  Number=4 Sum=`expr $Number + 1`  Note that it is necessary to separate the elements of the expression by spaces. An alternative is the arithmetic substitution $((expression))  Sum=$(($Number+1))  No spaces necessary. In both cases, echo $Sum gives 5.", 
            "title": "Shell Parameters"
        }, 
        {
            "location": "/linux_basics/#special-command-symbols", 
            "text": "", 
            "title": "Special Command Symbols"
        }, 
        {
            "location": "/linux_basics/#redirection", 
            "text": "file Reads input from the file file.   file Writes standard output to the file file; i.e., an old file with the same name will be overwritten.   file Appends standard output to the file file; i.e., the information will be added at the end of the file file, if it already exists.    2  file Writes standard error to the file file.   file Writes standard output and error to the file file.  myprog  outfile 2 errfile", 
            "title": "Redirection"
        }, 
        {
            "location": "/linux_basics/#command-execution", 
            "text": "; Separates multiple commands on the command line; i.e., the semi-colon corresponds to pressing ENTER between commands.  command1 ; command2  is the same as  command1 command2  | Pipe symbol. Uses output from one command as input for the next command; i.e.,  command1 | command2  is the same as  command1   outfile command2   outfile  !string repeats a previous command line that starts with the string string.  echo $PATH ... !echo  The last line corresponds to executing echo $PATH again.", 
            "title": "Command execution"
        }, 
        {
            "location": "/linux_basics/#quotation", 
            "text": "' ' (Single quotes) Quotes the enclosed string exactly.  Program=myprog\nJobNr=1\nOutputFile='${Program}_job$JobNr.out'\necho $OutputFile  gives ${Program}_job$JobNr.out as output.  \" \" (Double quotes) Quotes the enclosed string after variable substitution.  Program=myprog\nJobNr=1\nOutputFile=\"${Program}_job$JobNr.out\"\necho $OutputFile  gives myprog_job1.out as output", 
            "title": "Quotation"
        }, 
        {
            "location": "/linux_basics/#useful-linux-commands", 
            "text": "", 
            "title": "Useful Linux Commands"
        }, 
        {
            "location": "/linux_basics/#about-commands", 
            "text": "man  To get more information about a command type  man command  which  Check where the command that will be used resides  which command  This gives the path of the first occurence of command in the directories listed in the envrionment variable PATH. Note that a few commands are picked up directly by the shell, for example, the time command, and the program in the search path will not be executed. If a command behaves differently than expected from the man page, a solution may be to give the full path of the command found by which.", 
            "title": "About Commands"
        }, 
        {
            "location": "/linux_basics/#manage-shell-variables-and-parameters", 
            "text": "echo  Give the value of a parameter  echo $PATH  set  List the values of all defined environment variables alphabetically  set  export  Export a parameter to all future subshells  export parameter  The value can be set and exported at the same time, for example,  export MyParameter=myvalue", 
            "title": "Manage Shell Variables and Parameters"
        }, 
        {
            "location": "/linux_basics/#manage-files-and-directories", 
            "text": "mkdir  Make a directory  mkdir dirname  -p: Make a directory and also any parent directories, if they do not exist  mkdir -p parentdir1/parentdir2/dirname  rmdir  Remove an empty directory  rmdir dirname  cd  Change the current directory  cd dirname  Some special behaviour:  cd  Without a name the new directory is the home directory.  cd -  returns the user to the previous directory.  cd ..  moves up one level in the file tree.  rm  Remove a file  rm filename  -r: Remove a file or a directory with all files and directories in it  rm -r dirname  -i: Get a question before taking action (removing files, removing directories, descending in directories)  rm -ir dirname  mv  Change the name of a file or directory  mv oldname newname  cp  Copy a file to a new file  cp oldname newname  or to another directory  cp file1 file2 file3 newlocation  Copy all files in the current directory to another directory  cp * newlocation  -p: Copy with preserved file settings (modification date, permissions, ownership):  cp -p oldname newname  -r: Copy a directory and its subdirectories  cp -r oldname newname  -u: Copy only files that do not exist or have an earlier modification date in another directory  cp -u * newlocation  ls  List files in the current directory  ls  List the files in another directory  ls dirname  -l: List in long format  -s: List with size (in blocks by default)  -S: List sorted by size  -t: List sorted by time  -r: Reverse the order of a sorted listing  -h: Print size in human-readable form (with units adjusted to size)  List files in long format with most recent file last  ls -ltr  find  Find a file/directory with a given name and print its path, starting from a given directory  find dirname -name filename  Find all files that contain a specified string in their name, starting from the current directory  find . -name \"*string*\"  Find files newer than a specified file, starting from the current directory  find . -newer filename  -exec ... {} \\;: Execute a command with the found file represented by {}  Remove files and directories with a specified string in their name  find . -name \"*string*\" -exec rm -r {} \\;  -not: Negate an expression  -type d: Specify the file type as a directory  Get a long-format listing of files with a specified string in their name, as long as they are not directories  find . -name \"*string*\" -not -type d -exec ls -l {} \\;  find is a powerful command with many options as a look at the man page will reveal,  man find  du  Print the disk usage of the current and all subdirectories  du  Print the disk usage of a specifed directory and all its subdirectories  du dirname  -a: Print the size of individual files in addition to diectories  Print the size of a file  du -a filename  -s: Just print the sum of the disk usage  --max-depth=level: Print usage for directories level levels down, where level is a number  -k: Print usage in kB  -m: Print usage in MB  -h: Print usage in human-readable form (with units adjusted after the size)  Print the summed disk usage of the current directory in human-readable form  du -sh  Print the disk usage for the current directory and its immediate subdirectories in human-readable form  du -h --max-depth=1  chmod  Set the file permission.  Make a file executable for anyone  chmod +x filename  To be more precise it is possible to specify the changeas a string in the format who-add/remove-permission, where who is one of more of the characters u (user), g (group), and o (others); + means add and - means remove; and permission is one or more of the characters r (read), w (write), and x (execute). For example, to remove read and write permissions for the group and others  chmod go-rw filename  -R: Make the change recursively, i.e., for all files in all subdirectories  chmod -R g+w dirname", 
            "title": "Manage Files and Directories"
        }, 
        {
            "location": "/linux_basics/#text-handling", 
            "text": "cat  List the contents of a file  cat filename  List the contents of several files and put the result in a new file  cat file1 file2 file3   newfile  Append a file to another file  cat file1   file2  more  List the contents of a file without scrolling through everything at once  more filename  Display the output of a command without scrolling through everything at once  command | more  Pressing return gives a new line. Pressing the space bar gives a new page. b gives the previous page if possible (not for the output stream of a command). /string searches for a string. q exists more.  less  less is similar to more. One of the more important differences is that it also works backwards. For example, pressing b gives the previous page (works also for more on files - first more example, but not pipes - second more example) and ?string searches backwards for a string.  grep  Print lines that contain a specified string in a file  grep string filename  Search for and print lines containing a specified string in several files  grep string file1 file2 file3  Search for and print lines containing a specified string in all files in the current directory  grep string *  Print the lines in the output of a command containing a specified string  command | grep string  -i: Ignore the case of the search string (print both upper and lower case matches)  -v: Print lines that do not contain the string  command | grep -v string  diff  Compare the contents of two files and print differences  diff file1 file2  --side-by-side: Display the file contents side-by-side with differences marked  diff --side-by-side file1 file2", 
            "title": "Text Handling"
        }
    ]
}